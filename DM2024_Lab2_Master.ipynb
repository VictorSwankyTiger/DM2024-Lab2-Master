{
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4e5eiVLOYTp5"
      ],
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 594.85,
      "position": {
        "height": "40px",
        "left": "723px",
        "right": "20px",
        "top": "80px",
        "width": "250px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "none",
      "window_display": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2873526,
          "sourceType": "datasetVersion",
          "datasetId": 1759869
        },
        {
          "sourceId": 9687059,
          "sourceType": "datasetVersion",
          "datasetId": 5921883
        },
        {
          "sourceId": 9688199,
          "sourceType": "datasetVersion",
          "datasetId": 5922667
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorSwankyTiger/DM2024-Lab2-Master/blob/main/DM2024_Lab2_Master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "\n",
        "didiersalazar_lab2_dataset_path = kagglehub.dataset_download('didiersalazar/lab2-dataset')\n",
        "didiersalazar_pictures_path = kagglehub.dataset_download('didiersalazar/pictures')\n",
        "didiersalazar_google_news_vectors_path = kagglehub.dataset_download('didiersalazar/google-news-vectors')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSLkVzqpT2av",
        "outputId": "1832a118-a7ff-4c66-de21-168c89b7dcd5"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install scikit-learn --upgrade\n",
        "!pip3 install pandas --upgrade\n",
        "!pip3 install numpy --upgrade\n",
        "!pip3 install matplotlib --upgrade\n",
        "!pip3 install plotly --upgrade\n",
        "!pip3 install seaborn --upgrade\n",
        "!pip3 install nltk --upgrade\n",
        "!pip3 install umap-learn --upgrade\n",
        "\n",
        "!pip3 install gensim --upgrade\n",
        "#!pip3 install tensorflow --upgrade\n",
        "!pip3 install tensorflow==2.17.0\n",
        "!pip3 install keras --upgrade\n",
        "\n",
        "!pip3 install ollama --upgrade\n",
        "!pip3 install langchain --upgrade\n",
        "!pip3 install langchain_community --upgrade\n",
        "!pip3 install langchain_core --upgrade\n",
        "!pip3 install beautifulsoup4 --upgrade\n",
        "!pip3 install chromadb --upgrade\n",
        "!pip3 install gradio --upgrade"
      ],
      "metadata": {
        "id": "uuutyCx4YTpX",
        "execution": {
          "iopub.status.busy": "2024-10-22T03:39:34.071213Z",
          "iopub.execute_input": "2024-10-22T03:39:34.071789Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a925103-aa14-4938-fde3-0001906859f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.3 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\n",
            "langchain 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
            "langchain-community 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.1.3\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.1.3)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (2.1.3)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.5.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Collecting numpy>=1.17 (from umap-learn)\n",
            "  Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
            "Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.3\n",
            "    Uninstalling numpy-2.1.3:\n",
            "      Successfully uninstalled numpy-2.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "langchain 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "langchain-community 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Requirement already satisfied: tensorflow==2.17.0 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.17.0)\n",
            "  Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.6.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.17.0) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0) (0.1.2)\n",
            "Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.28.3\n",
            "    Uninstalling protobuf-5.28.3:\n",
            "      Successfully uninstalled protobuf-5.28.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-proto 1.28.1 requires protobuf<6.0,>=5.0, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-4.25.5\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama) (0.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.142)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.142)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.3.19)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (0.1.142)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_core) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_core) (3.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.23.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain_core) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain_core) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_core) (1.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.18)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.5)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.67.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.1.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.1)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Using cached protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-5.28.3\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.6.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.5)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.4.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.4.3)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.4)\n",
            "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.2)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import subprocess\n",
        "process = subprocess.Popen(\"ollama serve\", shell=True) #runs on a different thread"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD8Hrw1fT2ay",
        "outputId": "114cb4dc-3d6c-41d8-ea23-e71e6d1b6729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download model llama 3.2:1b\n",
        "!ollama pull llama3.2:1b"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7E5d6YnT2az",
        "outputId": "550e8f52-b10a-464d-ff08-8262e7cc9a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 74701a8c35f6... 100%  1.3 GB                         \n",
            "pulling 966de95ca8a6... 100%  1.4 KB                         \n",
            "pulling fcc5a6bec9da... 100%  7.7 KB                         \n",
            "pulling a70ff7e570d9... 100%  6.0 KB                         \n",
            "pulling 4f659a1e86d7... 100%   485 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download model llama 3.2\n",
        "!ollama pull llama3.2"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJi01m9MT2ay",
        "outputId": "51d9af72-bdf8-4ef5-c9d3-575a65059592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling dde5aa3fc5ff... 100%  2.0 GB                         \n",
            "pulling 966de95ca8a6... 100%  1.4 KB                         \n",
            "pulling fcc5a6bec9da... 100%  7.7 KB                         \n",
            "pulling a70ff7e570d9... 100%  6.0 KB                         \n",
            "pulling 56bb8bd477a5... 100%    96 B                         \n",
            "pulling 34bb5ab01051... 100%   561 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download model llava-phi3\n",
        "!ollama pull llava-phi3"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il6xJOJBT2az",
        "outputId": "2133f29a-93b6-4429-dec5-21a5992e6f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 377876be20ba... 100%  2.3 GB                         \n",
            "pulling 004fc0969720... 100%  607 MB                         \n",
            "pulling c608dc615584... 100%   149 B                         \n",
            "pulling cadf483f03b5... 100%   155 B                         \n",
            "pulling 3921dac664c1... 100%   492 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import umap\n",
        "import gensim\n",
        "import tensorflow\n",
        "import keras\n",
        "import ollama\n",
        "import langchain\n",
        "import langchain_community\n",
        "import langchain_core\n",
        "import bs4\n",
        "import chromadb\n",
        "import gradio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"gensim: \" + gensim.__version__)\n",
        "print(\"tensorflow: \" + tensorflow.__version__)\n",
        "print(\"keras: \" + keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmiZ5Yt_Wai5",
        "outputId": "f6d225e3-4527-49f7-fd47-6b58f26fa916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gensim: 4.3.3\n",
            "tensorflow: 2.17.0\n",
            "keras: 3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Mining Lab 2\n",
        "In this lab session we will focus on the use of Neural Word Embeddings and exploring some basic open source LLMs' applications to data."
      ],
      "metadata": {
        "id": "d9SJI0utT2az"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "1. Data preparation\n",
        "2. Feature engineering\n",
        "3. Model\n",
        "4. Results evaluation\n",
        "5. Other things you could try\n",
        "6. Deep Learning\n",
        "7. Word to Vector\n",
        "8. Clustering\n",
        "9. High-dimension Visualization\n",
        "10. Large Language Models (LLMs)\n"
      ],
      "metadata": {
        "id": "ledffNYYYTpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Necessary Library Requirements:\n",
        "\n",
        "#### Same as Lab1 except PAMI:\n",
        "- [Jupyter](http://jupyter.org/) (Strongly recommended but not required)\n",
        "    - Install via `pip3 install jupyter` and use `jupyter notebook` in terminal to run\n",
        "- [Scikit Learn](http://scikit-learn.org/stable/index.html)\n",
        "    - Install via `pip3 install scikit-learn` from a terminal\n",
        "- [Pandas](http://pandas.pydata.org/)\n",
        "    - Install via `pip3 install pandas` from a terminal\n",
        "- [Numpy](http://www.numpy.org/)\n",
        "    - Install via `pip3 install numpy` from a terminal\n",
        "- [Matplotlib](https://matplotlib.org/)\n",
        "    - Install via `pip3 install maplotlib` from a terminal\n",
        "- [Plotly](https://plot.ly/)\n",
        "    - Install via `pip3 install plotly` from a terminal\n",
        "- [Seaborn](https://seaborn.pydata.org/)\n",
        "    - Install via `pip3 install seaborn`\n",
        "- [NLTK](http://www.nltk.org/)\n",
        "    - Install via `pip3 install nltk` from a terminal\n",
        "- [UMAP](https://umap-learn.readthedocs.io/en/latest/)\n",
        "    - Install via `pip3 install umap-learn` from a terminal\n",
        "    \n",
        "\n",
        "#### New Libraries to install:\n",
        "- [Gensim](https://pypi.org/project/gensim/)\n",
        "    - Install via `pip3 install gensim`\n",
        "\n",
        "- [tensorflow](https://www.tensorflow.org/)\n",
        "    - Install via `pip3 install tensorflow`\n",
        "    - Also install `pip3 install tensorflow-hub`\n",
        "\n",
        "- [Keras](https://keras.io/)\n",
        "    - Install via `pip3 install keras`\n",
        "\n",
        "- [Ollama](https://ollama.com)\n",
        "    - Install via `pip3 install ollama`\n",
        "\n",
        "- [langchain](https://www.langchain.com)\n",
        "    - Install via `pip3 install langchain`\n",
        "    - Also install `pip3 install langchain_community`\n",
        "    - Also install `pip3 install langchain_core`\n",
        "    \n",
        "- [beautifulsoup4](https://pypi.org/project/beautifulsoup4/)\n",
        "    - Install via `pip3 install beautifulsoup4`\n",
        "    \n",
        "- [chromadb](https://www.trychroma.com)\n",
        "    - Install via `pip3 install chromadb`\n",
        "    \n",
        "- [gradio](https://www.gradio.app)\n",
        "    - Install via `pip3 install gradio`\n",
        "    \n",
        "#### Open-source LLMs to install:\n",
        "- ollama run llama3.2\n",
        "- ollama run llama3.2:1b  (optional if the first one is too big)\n",
        "- ollama run llava-phi3"
      ],
      "metadata": {
        "id": "YSEZMQOlT2a2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Introduction"
      ],
      "metadata": {
        "id": "LIpAqCvMYTpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
        "\n",
        "**Task:** Classify text data into 4 different emotions using word embeddings and other deep information retrieval approaches.\n",
        "\n",
        "![pic0.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic0.png?raw=true)"
      ],
      "metadata": {
        "id": "n2paPeNbYTpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1. Data Preparation"
      ],
      "metadata": {
        "id": "op_X7pR-YTpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before beggining the lab, please make sure to download the [Google News Dataset](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit) and place it in a folder named \"GoogleNews\" in the same directory as this file."
      ],
      "metadata": {
        "id": "ID-8I1ELYTpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Load data\n",
        "\n",
        "We start by loading the csv files into a single pandas dataframe for training and one for testing."
      ],
      "metadata": {
        "id": "pgoEbZzSYTpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "### training data\n",
        "anger_train = pd.read_csv(f\"{didiersalazar_lab2_dataset_path}/data/semeval/train/anger-ratings-0to1.train.txt\",\n",
        "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "sadness_train = pd.read_csv(f\"{didiersalazar_lab2_dataset_path}/data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "fear_train = pd.read_csv(f\"{didiersalazar_lab2_dataset_path}/data/semeval/train/fear-ratings-0to1.train.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "joy_train = pd.read_csv(f\"{didiersalazar_lab2_dataset_path}/data/semeval/train/joy-ratings-0to1.train.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
      ],
      "metadata": {
        "id": "anfjcPSSYTpX",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine 4 sub-dataset\n",
        "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
      ],
      "metadata": {
        "id": "yVc2T5MIYTpX",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### testing data\n",
        "anger_test = pd.read_csv(f\"{didiersalazar_lab2_dataset_path}/data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
        "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "sadness_test = pd.read_csv(f\"{didiersalazar_lab2_dataset_path}/data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "fear_test = pd.read_csv(f\"{didiersalazar_lab2_dataset_path}/data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "joy_test = pd.read_csv(f\"{didiersalazar_lab2_dataset_path}/data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "\n",
        "# combine 4 sub-dataset\n",
        "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw8bGMv7YTpX",
        "outputId": "08df8ba8-8f13-4b49-f820-ceac2098fe54",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text emotion  intensity\n",
              "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
              "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
              "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
              "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
              "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-796a0ae4-b8fa-4f4a-9be0-654343eba2c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>So my Indian Uber driver just called someone t...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-796a0ae4-b8fa-4f4a-9be0-654343eba2c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-796a0ae4-b8fa-4f4a-9be0-654343eba2c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-796a0ae4-b8fa-4f4a-9be0-654343eba2c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebaad025-8b31-4abe-9873-b26216996cda\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebaad025-8b31-4abe-9873-b26216996cda')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebaad025-8b31-4abe-9873-b26216996cda button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 3613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10715,\n        \"min\": 10000,\n        \"max\": 40785,\n        \"num_unique_values\": 3613,\n        \"samples\": [\n          10839,\n          30626,\n          10032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3565,\n        \"samples\": [\n          \"im literally shaking bc im nervous and bc its fucking cold oh how i love life\",\n          \"Halfway to work and I realize I forgot to put on underwear....It's going to be one of those days! #mombrain #toomuchgoingon #longday #breezy\",\n          \"Round 2  #pcola\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"fear\",\n          \"sadness\",\n          \"anger\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19036776242787684,\n        \"min\": 0.019,\n        \"max\": 0.98,\n        \"num_unique_values\": 403,\n        \"samples\": [\n          0.333,\n          0.673,\n          0.654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle dataset\n",
        "train_df = train_df.sample(frac=1)\n",
        "test_df = test_df.sample(frac=1)"
      ],
      "metadata": {
        "id": "HBHwcL8sYTpX",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of Training df: \", train_df.shape)\n",
        "print(\"Shape of Testing df: \", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w_cDUwCYTpX",
        "outputId": "c34c1d54-f712-4c9a-d325-263cafea9c51",
        "scrolled": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training df:  (3613, 4)\n",
            "Shape of Testing df:  (347, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ** >>> Exercise 1 (Take home): **  \n",
        "Plot word frequency for Top 30 words in both train and test dataset. (Hint: refer to DM lab 1)\n"
      ],
      "metadata": {
        "id": "escCgU1zYTpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n"
      ],
      "metadata": {
        "id": "HoXjet3pYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 1.2 Save data"
      ],
      "metadata": {
        "id": "_hr8aKhlYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will save our data in Pickle format. The pickle module implements binary protocols for serializing and de-serializing a Python object structure.   \n",
        "  \n",
        "Some advantages for using pickle structure:  \n",
        "* Because it stores the attribute type, it's more convenient for cross-platform use.  \n",
        "* When your data is huge, it could use less space to store also consume less loading time.   "
      ],
      "metadata": {
        "id": "Zm6GF2VvYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## save to pickle file\n",
        "train_df.to_pickle(\"train_df.pkl\")\n",
        "test_df.to_pickle(\"test_df.pkl\")"
      ],
      "metadata": {
        "id": "dZzepBdpYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "## load a pickle file\n",
        "train_df = pd.read_pickle(\"train_df.pkl\")\n",
        "test_df = pd.read_pickle(\"test_df.pkl\")"
      ],
      "metadata": {
        "id": "H5uO-kOUYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more information: https://reurl.cc/0Dzqx"
      ],
      "metadata": {
        "id": "_sLDcQzeYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 1.3 Exploratory data analysis (EDA)\n",
        "\n",
        "Again, before getting our hands dirty, we need to explore a little bit and understand the data we're dealing with."
      ],
      "metadata": {
        "id": "dKHpxTzLYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# group to find distribution\n",
        "train_df.groupby(['emotion']).count()['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLnEEliCYTpo",
        "outputId": "18d4041b-7b4e-4d77-fbf8-df1129192b1f",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "emotion\n",
              "anger       857\n",
              "fear       1147\n",
              "joy         823\n",
              "sadness     786\n",
              "Name: text, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>1147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# the histogram of the data\n",
        "labels = train_df['emotion'].unique()\n",
        "post_total = len(train_df)\n",
        "df1 = train_df.groupby(['emotion']).count()['text']\n",
        "df1 = df1.apply(lambda x: round(x*100/post_total,3))\n",
        "\n",
        "#plot\n",
        "fig, ax = plt.subplots(figsize=(5,3))\n",
        "plt.bar(df1.index,df1.values)\n",
        "\n",
        "#arrange\n",
        "plt.ylabel('% of instances')\n",
        "plt.xlabel('Emotion')\n",
        "plt.title('Emotion distribution')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcVOe8nYYTpo",
        "outputId": "37fa0a45-bbec-4bcd-d205-46740d6fda29",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAE8CAYAAABaaxFWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4G0lEQVR4nO3deVhUZf8/8PcAw7CD7BAILiiaiiaiqLkL7mvlo5bgQ1Zqmqkt/nxEUPualluFmqXQRouV9ZSKIiWauSsaaiS450JqQEAOE3P//vDiPGdkcUaGmXF8v65rLjn32T7nnpE358xZFEIIASIiIgIA2Ji7ACIiIkvCYCQiIpJhMBIREckwGImIiGQYjERERDIMRiIiIhkGIxERkQyDkYiISIbBSEREJMNgJDKCc+fOQaFQIC0tzdylSHr16oVevXpJw6asMS0tDQqFAufOnZPaQkNDMWTIkAZfNwDs3LkTCoUCO3fuNMn6yLowGMliVf1yre21b98+k9eUnp6OlStXmny95rR69WqLCnw5S66N7l8K3iuVLFVaWhomTpyIBQsWoEmTJtXGDxgwAN7e3iataciQIcjNzdXZEwIAIQTUajWUSiVsbW1NWlNtqvYWq/aa7rXGNm3awNvb26C9r8rKSmg0GqhUKigUCgC39xjbtGmD77//Xu/l3GttWq0WFRUVsLe3h40N//4nw9iZuwCiuxk4cCAiIyPNXUadFAoFHBwczF1GnUxRY1lZGZydnWFra2vWPxBsbGws/v0gy8U/pei+V/Xd2ZtvvomUlBQ0bdoUTk5OiImJwcWLFyGEwMKFCxEUFARHR0cMHz4cN2/erLac1atX4+GHH4ZKpUJgYCCmTp2KoqIiaXyvXr2wefNmnD9/XjqcGxoaqlPDnYf1fvjhBzz66KNwdnaGh4cHhg8fjlOnTulMk5SUBIVCgfz8fMTHx8PDwwPu7u6YOHEiysvL9eqDdevWoVmzZnB0dERUVBR2795daz/Ja7x69SomTpyIoKAgqFQqBAQEYPjw4dIecWhoKE6cOIHs7Gxpm6v2RKsOdWdnZ2PKlCnw9fVFUFCQzrg796wBYPv27Wjfvj0cHBzQunVrfP311zX2x53uXGZdtdX2HePGjRvRsWNHODo6wtvbG08++SR+//13nWni4+Ph4uKC33//HSNGjICLiwt8fHwwe/ZsVFZW1vIOkDXhHiNZvOLiYly/fl2nTaFQwMvLS6ftk08+QUVFBaZNm4abN29i6dKleOKJJ9CnTx/s3LkTr7zyCvLz8/H2229j9uzZ2LBhgzRvUlISkpOT0a9fP0yePBl5eXlYs2YNDh48iD179kCpVGLu3LkoLi7GpUuXsGLFCgCAi4tLrXXv2LEDAwcORNOmTZGUlIS///4bb7/9Nrp164YjR45IoVrliSeeQJMmTbB48WIcOXIE77//Pnx9fbFkyZI6+2f9+vV49tln0bVrV8yYMQNnzpzBsGHD4OnpieDg4DrnHT16NE6cOIFp06YhNDQUhYWFyMzMxIULFxAaGoqVK1di2rRpcHFxwdy5cwEAfn5+OsuYMmUKfHx8kJiYiLKysjrXd/r0aYwZMwbPPfcc4uLikJqaiscffxwZGRno379/nfPeSZ/a5KoOzXfq1AmLFy/GtWvXsGrVKuzZswdHjx6Fh4eHNG1lZSViY2PRuXNnvPnmm9ixYweWLVuGZs2aYfLkyQbVSfchQWShUlNTBYAaXyqVSpru7NmzAoDw8fERRUVFUvucOXMEABERESE0Go3UPnbsWGFvby9u3bolhBCisLBQ2Nvbi5iYGFFZWSlN98477wgAYsOGDVLb4MGDRUhISLVaq2pITU2V2tq3by98fX3FjRs3pLZjx44JGxsbMWHCBKlt/vz5AoD497//rbPMkSNHCi8vrzr7qKKiQvj6+or27dsLtVotta9bt04AED179qy1xj///FMAEG+88Uad63j44Yd1llOl6v3p3r27+Oeff2ocd/bsWaktJCREABBfffWV1FZcXCwCAgJEhw4dpLaq/qhtffJl1lbbjz/+KACIH3/8UQjxv35q06aN+Pvvv6Xpvv/+ewFAJCYmSm1xcXECgFiwYIHOMjt06CA6duxYbV1kfXgolSxeSkoKMjMzdV5bt26tNt3jjz8Od3d3abhz584AgCeffBJ2dnY67RUVFdIhtB07dqCiogIzZszQOVFj0qRJcHNzw+bNmw2u+cqVK8jJyUF8fDw8PT2l9nbt2qF///7YsmVLtXmee+45neFHH30UN27cQElJSa3rOXToEAoLC/Hcc8/B3t5eao+Pj9fpi5o4OjrC3t4eO3fuxJ9//qnvplUzadIkvb9PDAwMxMiRI6VhNzc3TJgwAUePHsXVq1fvuYa7qeqnKVOm6Hz3OHjwYISHh9f4Htf0fpw5c6bBaiTLwUOpZPGioqL0OvmmcePGOsNVwXDn4cSq9qowOH/+PACgZcuWOtPZ29ujadOm0nhD1LZMAGjVqhW2bdsmnahSW/2NGjWS6nRzc6tzPWFhYTrtSqUSTZs2rbNGlUqFJUuWYNasWfDz80OXLl0wZMgQTJgwAf7+/nfZwv+p6Yzh2jRv3rza94ctWrQAcPs7UEPWa4i63o/w8HD89NNPOm0ODg7w8fHRaWvUqFG9/oCg+wf3GMlq1LbXUlu7sLArlcxR54wZM/Dbb79h8eLFcHBwwLx589CqVSscPXpU72U4OjoataaaTrwBYNITXyzlkhsyDwYjPfBCQkIAAHl5eTrtFRUVOHv2rDQeqP2Xtr7LBIBff/0V3t7eOnuL96pqPadPn9Zp12g0OHv2rF7LaNasGWbNmoXt27cjNzcXFRUVWLZsmTRe323WR35+frWg/+233wBAOhmpak9ZfkYwgBr33I3xfuTl5em8x0QMRnrg9evXD/b29njrrbd0fmmvX78excXFGDx4sNTm7OyM4uLiuy4zICAA7du3xwcffKDzCz43Nxfbt2/HoEGDjFJ7ZGQkfHx8sHbtWlRUVEjtaWlp1YLlTuXl5bh165ZOW7NmzeDq6gq1Wi21OTs733VZ+rp8+TI2bdokDZeUlODDDz9E+/btpcOozZo1AwDs2rVLmq6srAwffPBBteXpW1tkZCR8fX2xdu1anW3bunUrTp06pfMeE/E7RrJ4W7duxa+//lqtvWvXrnf9Hk0fPj4+mDNnDpKTkzFgwAAMGzYMeXl5WL16NTp16oQnn3xSmrZjx474/PPPMXPmTHTq1AkuLi4YOnRojct94403MHDgQERHRyMhIUG6XMPd3R1JSUn1rhu4/V3iokWL8Oyzz6JPnz4YM2YMzp49i9TU1Lv2zW+//Ya+ffviiSeeQOvWrWFnZ4dNmzbh2rVr+Ne//qWzzWvWrMGiRYvQvHlz+Pr6ok+fPvdUb4sWLZCQkICDBw/Cz88PGzZswLVr15CamipNExMTg8aNGyMhIQEvvfQSbG1tsWHDBvj4+ODChQs6y9O3NqVSiSVLlmDixIno2bMnxo4dK12uERoaihdffPGetoeslHlPiiWqXV2Xa0B22UHVZQh3XnZQdcr+xo0ba1zuwYMHddrfeecdER4eLpRKpfDz8xOTJ08Wf/75p840paWlYty4ccLDw0MAkC7dqOlyDSGE2LFjh+jWrZtwdHQUbm5uYujQoeLkyZM601RdnvDHH3/UWKf88oTarF69WjRp0kSoVCoRGRkpdu3aJXr27Fnn5RrXr18XU6dOFeHh4cLZ2Vm4u7uLzp07iy+++EJn2VevXhWDBw8Wrq6uOpeA1NaPtdUeEhIiBg8eLLZt2ybatWsnVCqVCA8Pr/b+CCHE4cOHRefOnYW9vb1o3LixWL58eY3LrK22Oy/XqPL555+LDh06CJVKJTw9PcX48ePFpUuXdKaJi4sTzs7O1Wqq7TISsj68VyoREZEMv2MkIiKSYTASERHJMBiJiIhkGIxEREQyDEYiIiIZBiMREZGM1V/gr9VqcfnyZbi6uhr11lZERHT/EELgr7/+QmBgoM5TdGpi9cF4+fLluz6slYiIHgwXL15EUFBQndNYfTC6uroCuN0ZtT26536l0Wiwfft2xMTEQKlUmrscq8f+Nj32uelZa5+XlJQgODhYyoS6WH0wVh0+dXNzs8pgdHJygpubm1V9gC0V+9v02OemZ+19rs9Xajz5hoiISIbBSEREJMNgJCIikmEwEhERyTAYiYiIZBiMREREMgxGIiIiGQYjERGRjNVf4E/3r9BXN5u7BB0qW4GlUUCbpG1QV1rOfXfPvT7Y3CUQWRXuMRIREckwGImIiGQYjERERDIMRiIiIhkGIxERkQyDkYiISIbBSEREJGPWYFyzZg3atWsnPUQ4OjoaW7dulcbfunULU6dOhZeXF1xcXDB69Ghcu3bNjBUTEZG1M2swBgUF4fXXX8fhw4dx6NAh9OnTB8OHD8eJEycAAC+++CK+++47bNy4EdnZ2bh8+TJGjRplzpKJiMjKmfXON0OHDtUZfu2117BmzRrs27cPQUFBWL9+PdLT09GnTx8AQGpqKlq1aoV9+/ahS5cu5iiZiIisnMXcEq6yshIbN25EWVkZoqOjcfjwYWg0GvTr10+aJjw8HI0bN8bevXtrDUa1Wg21Wi0Nl5SUAAA0Gg00Gk3DboSJVW2PtW1XFZWtMHcJOlQ2QudfS2Gt7z9g/Z9xS2StfW7I9pg9GH/55RdER0fj1q1bcHFxwaZNm9C6dWvk5OTA3t4eHh4eOtP7+fnh6tWrtS5v8eLFSE5Orta+fft2ODk5Gbt8i5CZmWnuEhrE0ihzV1CzhZFac5egY8uWLeYuocFZ62fckllbn5eXl+s9rdmDsWXLlsjJyUFxcTG+/PJLxMXFITs7+56XN2fOHMycOVMaLikpQXBwMGJiYuDm5maMki2GRqNBZmYm+vfvD6VSae5yjK5N0jZzl6BDZSOwMFKLeYdsoNZazk3Ec5NizV1Cg7H2z7glstY+rzp6qA+zB6O9vT2aN28OAOjYsSMOHjyIVatWYcyYMaioqEBRUZHOXuO1a9fg7+9f6/JUKhVUKlW1dqVSaVVvspy1bpslPcFCTq1VWFRt1vje38laP+OWzNr63JBtsbjrGLVaLdRqNTp27AilUomsrCxpXF5eHi5cuIDo6GgzVkhERNbMrHuMc+bMwcCBA9G4cWP89ddfSE9Px86dO7Ft2za4u7sjISEBM2fOhKenJ9zc3DBt2jRER0fzjFQiImowZg3GwsJCTJgwAVeuXIG7uzvatWuHbdu2oX///gCAFStWwMbGBqNHj4ZarUZsbCxWr15tzpKJiMjKmTUY169fX+d4BwcHpKSkICUlxUQVERHRg87ivmMkIiIyJwYjERGRDIORiIhIhsFIREQkw2AkIiKSYTASERHJMBiJiIhkGIxEREQyDEYiIiIZBiMREZEMg5GIiEiGwUhERCTDYCQiIpJhMBIREckwGImIiGQYjERERDIMRiIiIhkGIxERkQyDkYiISIbBSEREJMNgJCIikmEwEhERyTAYiYiIZBiMREREMmYNxsWLF6NTp05wdXWFr68vRowYgby8PJ1pevXqBYVCofN67rnnzFQxERFZO7MGY3Z2NqZOnYp9+/YhMzMTGo0GMTExKCsr05lu0qRJuHLlivRaunSpmSomIiJrZ2fOlWdkZOgMp6WlwdfXF4cPH0aPHj2kdicnJ/j7++u1TLVaDbVaLQ2XlJQAADQaDTQajRGqthxV22Nt21VFZSvMXYIOlY3Q+ddSWOv7D1j/Z9wSWWufG7I9CiGExfwvz8/PR1hYGH755Re0adMGwO1DqSdOnIAQAv7+/hg6dCjmzZsHJyenGpeRlJSE5OTkau3p6em1zkNERNatvLwc48aNQ3FxMdzc3Oqc1mKCUavVYtiwYSgqKsJPP/0kta9btw4hISEIDAzE8ePH8corryAqKgpff/11jcupaY8xODgY169fv2tn3G80Gg0yMzPRv39/KJVKc5djdG2Stpm7BB0qG4GFkVrMO2QDtVZh7nIkuUmx5i6hwVj7Z9wSWWufl5SUwNvbW69gNOuhVLmpU6ciNzdXJxQB4JlnnpF+btu2LQICAtC3b18UFBSgWbNm1ZajUqmgUqmqtSuVSqt6k+WsddvUlZYTPnJqrcKiarPG9/5O1voZt2TW1ueGbItFXK7x/PPP4/vvv8ePP/6IoKCgOqft3LkzgNuHXYmIiIzNrHuMQghMmzYNmzZtws6dO9GkSZO7zpOTkwMACAgIaODqiIjoQWTWYJw6dSrS09Px7bffwtXVFVevXgUAuLu7w9HREQUFBUhPT8egQYPg5eWF48eP48UXX0SPHj3Qrl07c5ZORERWyqzBuGbNGgC3zzyVS01NRXx8POzt7bFjxw6sXLkSZWVlCA4OxujRo/Gf//zHDNUSEdGDwOyHUusSHByM7OxsE1VDRERkISffEBERWQqD9xgvXrwIhUIhnT164MABpKeno3Xr1jqXVlij0Fc3m7sEHSpbgaVRt6/3s6TLB869PtjcJRAR3TOD9xjHjRuHH3/8EQBw9epV9O/fHwcOHMDcuXOxYMECoxdIRERkSgYHY25uLqKiogAAX3zxBdq0aYOff/4Zn3zyCdLS0oxdHxERkUkZHIwajUa6s8yOHTswbNgwAEB4eDiuXLli3OqIiIhMzOBgfPjhh7F27Vrs3r0bmZmZGDBgAADg8uXL8PLyMnqBREREpmRwMC5ZsgTvvvsuevXqhbFjxyIiIgIA8N///lc6xEpERHS/Mvis1F69euH69esoKSlBo0aNpPZnnnmGj3UiIqL73j1d4C+EwOHDh1FQUIBx48bB1dUV9vb2DEai+xwvSdIPL0mybgYH4/nz5zFgwABcuHABarUa/fv3h6urK5YsWQK1Wo21a9c2RJ1EREQmYfB3jC+88AIiIyPx559/wtHRUWofOXIksrKyjFocERGRqRm8x7h79278/PPPsLe312kPDQ3F77//brTCiIiIzMHgPUatVovKyspq7ZcuXYKrq6tRiiIiIjIXg4MxJiYGK1eulIYVCgVKS0sxf/58DBo0yJi1ERERmZzBh1KXLVuG2NhYtG7dGrdu3cK4ceNw+vRpeHt749NPP22IGomIiEzG4GAMCgrCsWPH8Pnnn+PYsWMoLS1FQkICxo8fr3MyDhER3R0vkdGPKS+RuafrGO3s7DB+/HiMHz/e2PUQERGZlcHfMS5evBgbNmyo1r5hwwYsWbLEKEURERGZi8HB+O677yI8PLxae9XNxYmIiO5nBgfj1atXERAQUK3dx8eHj50iIqL7nsHBGBwcjD179lRr37NnDwIDA41SFBERkbkYfPLNpEmTMGPGDGg0GvTp0wcAkJWVhZdffhmzZs0yeoFERESmZHAwvvTSS7hx4wamTJmCiooKAICDgwNeeeUVzJkzx+gFEhERmZLBh1IVCgWWLFmCP/74A/v27cOxY8dw8+ZNJCYmGrzyxYsXo1OnTnB1dYWvry9GjBiBvLw8nWlu3bqFqVOnwsvLCy4uLhg9ejSuXbtm8LqIiIj0YXAwVnFxcUGnTp3Qpk0bqFSqe1pGdnY2pk6din379iEzMxMajQYxMTEoKyuTpnnxxRfx3XffYePGjcjOzsbly5cxatSoey2biIioTgYfSi0rK8Prr7+OrKwsFBYWQqvV6ow/c+aM3svKyMjQGU5LS4Ovry8OHz6MHj16oLi4GOvXr0d6err0fWZqaipatWqFffv2oUuXLoaWT0REVCeDg/Hpp59GdnY2nnrqKQQEBEChMN4tg4qLiwEAnp6eAIDDhw9Do9GgX79+0jTh4eFo3Lgx9u7dW2MwqtVqqNVqabikpAQAoNFooNFo6lWfylbUa35jU9kInX8tRX37uQr7Wz/G6m+Afa4v9rnp1bfPDZlfIYQwaOs9PDywefNmdOvWzeDC6qLVajFs2DAUFRXhp59+AgCkp6dj4sSJOkEHAFFRUejdu3eNd9pJSkpCcnJytfb09HQ4OTkZtWYiIro/lJeXY9y4cSguLoabm1ud0xq8x9ioUSNpj86Ypk6ditzcXCkU79WcOXMwc+ZMabikpATBwcGIiYm5a2fcTZukbfWa39hUNgILI7WYd8gGaq3l3Ow3NynWKMthf+vHWP0NsM/1xT43vfr2edXRQ30YHIwLFy5EYmIiPvjgA6PtgT3//PP4/vvvsWvXLgQFBUnt/v7+qKioQFFRETw8PKT2a9euwd/fv8ZlqVSqGk8GUiqVUCqV9arTku40L6fWKiyqtvr2cxVL2iY5a+1vgH2uL/a56dW3zw2Z/56ex1hQUAA/Pz+EhoZWW9mRI0f0XpYQAtOmTcOmTZuwc+dONGnSRGd8x44doVQqkZWVhdGjRwMA8vLycOHCBURHRxtaOhER0V0ZHIwjRoww2sqnTp2K9PR0fPvtt3B1dcXVq1cBAO7u7nB0dIS7uzsSEhIwc+ZMeHp6ws3NDdOmTUN0dDTPSCUiogZhcDDOnz/faCtfs2YNAKBXr1467ampqYiPjwcArFixAjY2Nhg9ejTUajViY2OxevVqo9VAREQkd08PKjYWfU6IdXBwQEpKClJSUkxQERERPegMDsbKykqsWLECX3zxBS5cuCDdL7XKzZs3jVYcERGRqRl8S7jk5GQsX74cY8aMQXFxMWbOnIlRo0bBxsYGSUlJDVAiERGR6RgcjJ988gnee+89zJo1C3Z2dhg7dizef/99JCYmYt++fQ1RIxERkckYHIxXr15F27ZtAdy+kXjVbdyGDBmCzZs3G7c6IiIiEzM4GIOCgnDlyhUAQLNmzbB9+3YAwMGDB+/5KRtERESWwuBgHDlyJLKysgAA06ZNw7x58xAWFoYJEybg3//+t9ELJCIiMiWDz0p9/fXXpZ/HjBmDkJAQ/PzzzwgLC8PQoUONWhwREZGpGRyMu3btQteuXWFnd3vWLl26oEuXLvjnn3+wa9cu9OjRw+hFEhERmYrBh1J79+5d47WKxcXF6N27t1GKIiIiMheDg1EIUePDiW/cuAFnZ2ejFEVERGQueh9KHTVqFABAoVAgPj5e5wzUyspKHD9+HF27djV+hURERCakdzC6u7sDuL3H6OrqCkdHR2mcvb09unTpgkmTJhm/QiIiIhPSOxhTU1MBAKGhoZg9ezYPmxIRkVUy+DvGl19+Wec7xvPnz2PlypXShf5ERET3M4ODcfjw4fjwww8BAEVFRYiKisKyZcswfPhw6fmKRERE9yuDg/HIkSN49NFHAQBffvkl/P39cf78eXz44Yd46623jF4gERGRKRkcjOXl5XB1dQUAbN++XXrkVJcuXXD+/HmjF0hERGRKBgdj8+bN8c033+DixYvYtm0bYmJiAACFhYVwc3MzeoFERESmZHAwJiYmYvbs2QgNDUXnzp0RHR0N4PbeY4cOHYxeIBERkSkZfK/Uxx57DN27d8eVK1cQEREhtfft2xcjR440anFERESmZnAwAoC/vz/8/f112qKiooxSEBERkTkZHIxlZWV4/fXXkZWVhcLCQmi1Wp3xZ86cMVpxREREpmZwMD799NPIzs7GU089hYCAgBpvKE5ERHS/MjgYt27dis2bN6Nbt24NUQ8REZFZGXxWaqNGjeDp6WmUle/atQtDhw5FYGAgFAoFvvnmG53x8fHxUCgUOq8BAwYYZd1EREQ1MTgYFy5ciMTERJSXl9d75WVlZYiIiEBKSkqt0wwYMABXrlyRXp9++mm910tERFQbgw+lLlu2DAUFBfDz80NoaCiUSqXO+CNHjui9rIEDB2LgwIF1TqNSqaqdAUtERNRQDA7GESNGNEAZtdu5cyd8fX3RqFEj9OnTB4sWLYKXl1et06vVaqjVamm4pKQEAKDRaKDRaOpVi8pW1Gt+Y1PZCJ1/LUV9+7kK+1s/xupvgH2uL/a56dW3zw2ZXyGEsIitVygU2LRpk07wfvbZZ3ByckKTJk1QUFCA//f//h9cXFywd+9e2Nra1ricpKQkJCcnV2tPT0+Hk5NTQ5VPREQWrLy8HOPGjUNxcfFdb19q0cF4pzNnzqBZs2bYsWMH+vbtW+M0Ne0xBgcH4/r16/W+l2ubpG31mt/YVDYCCyO1mHfIBmqt5Vw2k5sUa5TlsL/1Y6z+Btjn+mKfm159+7ykpATe3t56BaNeh1I9PT3x22+/wdvbG40aNarz2sWbN28aVq0BmjZtCm9vb+Tn59cajCqVCiqVqlq7Uqms9n2oodSVlvMhkVNrFRZVW337uYolbZOctfY3wD7XF/vc9Orb54bMr1cwrlixQnrU1MqVK++pKGO4dOkSbty4gYCAALPVQERE1k2vYIyLi6vx5/oqLS1Ffn6+NHz27Fnk5OTA09MTnp6eSE5OxujRo+Hv74+CggK8/PLLaN68OWJjjXcYg4iISO6ebiJuLIcOHULv3r2l4ZkzZwK4Hb5r1qzB8ePH8cEHH6CoqAiBgYGIiYnBwoULazxUSkREZAxmDcZevXqhrnN/tm2zrC+liYjI+hl85xsiIiJrplcwHj9+vNrjpYiIiKyRXsHYoUMHXL9+HcDtSyZu3LjRoEURERGZi17B6OHhgbNnzwIAzp07x71HIiKyWnqdfDN69Gj07NlTejBxZGRkrbdkO3PmjFELJCIiMiW9gnHdunUYNWoU8vPzMX36dEyaNEm64J+IiMia6H25RtUDgg8fPowXXniBwUhERFbJ4OsYU1NTpZ8vXboEAAgKCjJeRURERGZk8HWMWq0WCxYsgLu7O0JCQhASEgIPDw8sXLiQJ+UQEdF9z+A9xrlz52L9+vV4/fXX0a1bNwDATz/9hKSkJNy6dQuvvfaa0YskIiIyFYOD8YMPPsD777+PYcOGSW3t2rXDQw89hClTpjAYiYjovmbwodSbN28iPDy8Wnt4eHiDPouRiIjIFAwOxoiICLzzzjvV2t955x1EREQYpSgiIiJzMfhQ6tKlSzF48GDs2LED0dHRAIC9e/fi4sWL2LJli9ELJCIiMiWD9xh79uyJ3377DSNHjkRRURGKioowatQo5OXl4dFHH22IGomIiEzmnp7HGBgYyJNsiIjIKvF5jERERDIMRiIiIhkGIxERkQyDkYiISOaeTr6pcv36dezfvx+VlZXo1KkTAgICjFUXERGRWdxzMH711VdISEhAixYtoNFokJeXh5SUFEycONGY9REREZmU3odSS0tLdYaTk5Nx4MABHDhwAEePHsXGjRsxd+5coxdIRERkSnoHY8eOHfHtt99Kw3Z2digsLJSGr127Bnt7e+NWR0REZGJ6B+O2bduwbt06jBw5EpcvX8aqVaswZswY+Pv7w9vbG6+++ipWr15t0Mp37dqFoUOHIjAwEAqFAt98843OeCEEEhMTERAQAEdHR/Tr1w+nT582aB1ERESG0DsYQ0NDsXnzZjzxxBPo2bMncnJykJ+fj8zMTOzYsQMXLlzAoEGDDFp5WVkZIiIikJKSUuP4pUuX4q233sLatWuxf/9+ODs7IzY2Frdu3TJoPURERPoy+OSbsWPHYuDAgZg9ezZ69eqFdevWoX379ve08oEDB2LgwIE1jhNCYOXKlfjPf/6D4cOHAwA+/PBD+Pn54ZtvvsG//vWvGudTq9VQq9XScElJCQBAo9FAo9HcU51VVLaiXvMbm8pG6PxrKerbz1XY3/oxVn8D7HN9sc9Nr759bsj8CiGE3lu/ZcsWnDp1ChEREejXrx+ys7MxdepUDBw4EAsWLICjo+M9FQwACoUCmzZtwogRIwAAZ86cQbNmzXD06FGd4O3Zsyfat2+PVatW1bicpKQkJCcnV2tPT0+Hk5PTPddHRET3r/LycowbNw7FxcVwc3Orc1q99xhnzZqFjz/+GL1798bq1asRHx+PefPm4ciRI1i4cCE6dOiAFStW1LoHaKirV68CAPz8/HTa/fz8pHE1mTNnDmbOnCkNl5SUIDg4GDExMXftjLtpk7StXvMbm8pGYGGkFvMO2UCtVZi7HEluUqxRlsP+1o+x+htgn+uLfW569e3zqqOH+tA7GNPS0rB9+3Z07NgRN2/eRJcuXTBv3jzY29tj4cKFGDt2LJ599lmjBeO9UqlUUKlU1dqVSiWUSmW9lq2utJwPiZxaq7Co2urbz1UsaZvkrLW/Afa5vtjnplffPjdkfr1PvnF2dsbZs2cBABcvXoSDg4PO+NatW2P37t16r/hu/P39Ady+DETu2rVr0jgiIiJj0zsYFy9ejAkTJiAwMBA9e/bEwoULG7IuNGnSBP7+/sjKypLaSkpKsH//fkRHRzfouomI6MGl96HU8ePHY8CAAThz5gzCwsLg4eFR75WXlpYiPz9fGj579ixycnLg6emJxo0bY8aMGVi0aBHCwsLQpEkTzJs3D4GBgdIJOkRERMZm0OUaXl5e8PLyMtrKDx06hN69e0vDVSfNxMXFIS0tDS+//DLKysrwzDPPoKioCN27d0dGRka1w7hERETGUq+na9RXr169UNfVIgqFAgsWLMCCBQtMWBURET3I+DxGIiIiGQYjERGRDIORiIhIhsFIREQkw2AkIiKSYTASERHJMBiJiIhkGIxEREQyDEYiIiIZBiMREZEMg5GIiEiGwUhERCTDYCQiIpJhMBIREckwGImIiGQYjERERDIMRiIiIhkGIxERkQyDkYiISIbBSEREJMNgJCIikmEwEhERyTAYiYiIZCw6GJOSkqBQKHRe4eHh5i6LiIismJ25C7ibhx9+GDt27JCG7ewsvmQiIrqPWXzK2NnZwd/f39xlEBHRA8Lig/H06dMIDAyEg4MDoqOjsXjxYjRu3LjW6dVqNdRqtTRcUlICANBoNNBoNPWqRWUr6jW/salshM6/lqK+/VyF/a0fY/U3wD7XF/vc9Orb54bMrxBCWNbWy2zduhWlpaVo2bIlrly5guTkZPz+++/Izc2Fq6trjfMkJSUhOTm5Wnt6ejqcnJwaumQiIrJA5eXlGDduHIqLi+Hm5lbntBYdjHcqKipCSEgIli9fjoSEhBqnqWmPMTg4GNevX79rZ9xNm6Rt9Zrf2FQ2AgsjtZh3yAZqrcLc5Uhyk2KNshz2t36M1d8A+1xf7HPTq2+fl5SUwNvbW69gtPhDqXIeHh5o0aIF8vPza51GpVJBpVJVa1cqlVAqlfVav7rScj4kcmqtwqJqq28/V7GkbZKz1v4G2Of6Yp+bXn373JD5LfpyjTuVlpaioKAAAQEB5i6FiIislEUH4+zZs5GdnY1z587h559/xsiRI2Fra4uxY8eauzQiIrJSFn0o9dKlSxg7dixu3LgBHx8fdO/eHfv27YOPj4+5SyMiIitl0cH42WefmbsEIiJ6wFj0oVQiIiJTYzASERHJMBiJiIhkGIxEREQyDEYiIiIZBiMREZEMg5GIiEiGwUhERCTDYCQiIpJhMBIREckwGImIiGQYjERERDIMRiIiIhkGIxERkQyDkYiISIbBSEREJMNgJCIikmEwEhERyTAYiYiIZBiMREREMgxGIiIiGQYjERGRDIORiIhIhsFIREQkc18EY0pKCkJDQ+Hg4IDOnTvjwIED5i6JiIislMUH4+eff46ZM2di/vz5OHLkCCIiIhAbG4vCwkJzl0ZERFbI4oNx+fLlmDRpEiZOnIjWrVtj7dq1cHJywoYNG8xdGhERWSE7cxdQl4qKChw+fBhz5syR2mxsbNCvXz/s3bu3xnnUajXUarU0XFxcDAC4efMmNBpNveqx+6esXvMbm51WoLxcCzuNDSq1CnOXI7lx44ZRlsP+1o+x+htgn+uLfW569e3zv/76CwAghLj7xMKC/f777wKA+Pnnn3XaX3rpJREVFVXjPPPnzxcA+OKLL7744qva6+LFi3fNHoveY7wXc+bMwcyZM6VhrVaLmzdvwsvLCwqF5fz1YwwlJSUIDg7GxYsX4ebmZu5yrB772/TY56ZnrX0uhMBff/2FwMDAu05r0cHo7e0NW1tbXLt2Taf92rVr8Pf3r3EelUoFlUql0+bh4dFQJVoENzc3q/oAWzr2t+mxz03PGvvc3d1dr+ks+uQbe3t7dOzYEVlZWVKbVqtFVlYWoqOjzVgZERFZK4veYwSAmTNnIi4uDpGRkYiKisLKlStRVlaGiRMnmrs0IiKyQhYfjGPGjMEff/yBxMREXL16Fe3bt0dGRgb8/PzMXZrZqVQqzJ8/v9qhY2oY7G/TY5+bHvscUAihz7mrREREDwaL/o6RiIjI1BiMREREMgxGIiIiGQYjPdCEEHjmmWfg6ekJhUKBnJwcc5f0QImPj8eIESPMXcYDSaFQ4JtvvjF3GRbJ4s9KJWpIGRkZSEtLw86dO9G0aVN4e3ubu6QHyqpVq/S7dyWRCTEYSaLRaKBUKs1dhkkVFBQgICAAXbt2bbB1VFRUwN7evsGWfz/T904kRKbEQ6lmkJGRge7du8PDwwNeXl4YMmQICgoKAADnzp2DQqHA119/jd69e8PJyQkRERHVniby3nvvITg4GE5OThg5ciSWL19e7dZ33377LR555BE4ODigadOmSE5Oxj///CONVygUWLNmDYYNGwZnZ2e89tprDb7tliQ+Ph7Tpk3DhQsXoFAoEBoaCq1Wi8WLF6NJkyZwdHREREQEvvzyS2meyspKJCQkSONbtmyJVatWVVvuiBEj8NprryEwMBAtW7Y09abdN+SHUtVqNaZPnw5fX184ODige/fuOHjwIIDbh7ybN2+ON998U2f+nJwcKBQK5Ofnm7p0k/vyyy/Rtm1bODo6wsvLC/369UNZWRkOHjyI/v37w9vbG+7u7ujZsyeOHDmiM+/p06fRo0cPODg4oHXr1sjMzNQZr+/vnZ9++gmPPvooHB0dERwcjOnTp6Os7H9PB1m9ejXCwsLg4OAAPz8/PPbYY3et3yLV8wEYdA++/PJL8dVXX4nTp0+Lo0ePiqFDh4q2bduKyspKcfbsWQFAhIeHi++//17k5eWJxx57TISEhAiNRiOEEOKnn34SNjY24o033hB5eXkiJSVFeHp6Cnd3d2kdu3btEm5ubiItLU0UFBSI7du3i9DQUJGUlCRNA0D4+vqKDRs2iIKCAnH+/HlTd4VZFRUViQULFoigoCBx5coVUVhYKBYtWiTCw8NFRkaGKCgoEKmpqUKlUomdO3cKIYSoqKgQiYmJ4uDBg+LMmTPi448/Fk5OTuLzzz+XlhsXFydcXFzEU089JXJzc0Vubq65NtHixcXFieHDhwshhJg+fboIDAwUW7ZsESdOnBBxcXGiUaNG4saNG0IIIV577TXRunVrnfmnT58uevToYeqyTe7y5cvCzs5OLF++XJw9e1YcP35cpKSkiL/++ktkZWWJjz76SJw6dUqcPHlSJCQkCD8/P1FSUiKEEKKyslK0adNG9O3bV+Tk5Ijs7GzRoUMHAUBs2rRJCCH0+r2Tn58vnJ2dxYoVK8Rvv/0m9uzZIzp06CDi4+OFEEIcPHhQ2NraivT0dHHu3Dlx5MgRsWrVqrvWb4kYjBbgjz/+EADEL7/8In1A33//fWn8iRMnBABx6tQpIYQQY8aMEYMHD9ZZxvjx43WCsW/fvuL//u//dKb56KOPREBAgDQMQMyYMaMBtuj+sWLFChESEiKEEOLWrVvCycmp2mPOEhISxNixY2tdxtSpU8Xo0aOl4bi4OOHn5yfUanWD1GxNqoKxtLRUKJVK8cknn0jjKioqRGBgoFi6dKkQ4vZj6GxtbcX+/ful8d7e3iItLc0stZvS4cOHBQBx7ty5u05bWVkpXF1dxXfffSeEEGLbtm3Czs5O/P7779I0W7durTEY6/q9k5CQIJ555hmdde3evVvY2NiIv//+W3z11VfCzc1NCuR7rd8S8FCqGZw+fRpjx45F06ZN4ebmhtDQUADAhQsXpGnatWsn/RwQEAAAKCwsBADk5eUhKipKZ5l3Dh87dgwLFiyAi4uL9Jo0aRKuXLmC8vJyabrIyEijbtv9LD8/H+Xl5ejfv79Ov3344YfSoW4ASElJQceOHeHj4wMXFxesW7dO570DgLZt2/J7RQMUFBRAo9GgW7duUptSqURUVBROnToFAAgMDMTgwYOxYcMGAMB3330HtVqNxx9/3Cw1m1JERAT69u2Ltm3b4vHHH8d7772HP//8E8Dtpw1NmjQJYWFhcHd3h5ubG0pLS6XP5KlTpxAcHKzzuKXaHsJQ1++dY8eOIS0tTef/RmxsLLRaLc6ePYv+/fsjJCQETZs2xVNPPYVPPvlE+l1TV/2WiCffmMHQoUMREhKC9957D4GBgdBqtWjTpg0qKiqkaeQnwVQ9R1Kr1eq9jtLSUiQnJ2PUqFHVxjk4OEg/Ozs738smWKXS0lIAwObNm/HQQw/pjKu6b+Rnn32G2bNnY9myZYiOjoarqyveeOMN7N+/X2d69mvDePrpp/HUU09hxYoVSE1NxZgxY+Dk5GTushqcra0tMjMz8fPPP2P79u14++23MXfuXOzfvx+TJ0/GjRs3sGrVKoSEhEClUiE6Olrn94m+6vq9U1paimeffRbTp0+vNl/jxo1hb2+PI0eOYOfOndi+fTsSExORlJSEgwcPwsPDo9b6mzRpco+90nAYjCZ248YN5OXl4b333sOjjz4K4PYX2oZo2bKldFJClTuHH3nkEeTl5aF58+b1K/gB0rp1a6hUKly4cAE9e/ascZo9e/aga9eumDJlitQm35uke9OsWTPY29tjz549CAkJAXD7LOmDBw9ixowZ0nSDBg2Cs7Mz1qxZg4yMDOzatctMFZueQqFAt27d0K1bNyQmJiIkJASbNm3Cnj17sHr1agwaNAgAcPHiRVy/fl2ar1WrVrh48SKuXLki7QXu27fP4PU/8sgjOHnyZJ2/U+zs7NCvXz/069cP8+fPh4eHB3744QeMGjWq1vrlD5a3FAxGE2vUqBG8vLywbt06BAQE4MKFC3j11VcNWsa0adPQo0cPLF++HEOHDsUPP/yArVu3Sn/hAUBiYiKGDBmCxo0b47HHHoONjQ2OHTuG3NxcLFq0yNibZRVcXV0xe/ZsvPjii9BqtejevTuKi4uxZ88euLm5IS4uDmFhYfjwww+xbds2NGnSBB999BEOHjxokX/13k+cnZ0xefJkvPTSS/D09ETjxo2xdOlSlJeXIyEhQZrO1tYW8fHxmDNnDsLCwh6Y57Lu378fWVlZiImJga+vL/bv348//vgDrVq1QlhYGD766CNERkaipKQEL730EhwdHaV5+/XrhxYtWiAuLg5vvPEGSkpKMHfuXINreOWVV9ClSxc8//zzePrpp+Hs7IyTJ08iMzMT77zzDr7//nucOXMGPXr0QKNGjbBlyxZotVq0bNmyzvotkrm/5HwQZWZmilatWgmVSiXatWsndu7cKX0RXvUl+NGjR6Xp//zzTwFA/Pjjj1LbunXrxEMPPSQcHR3FiBEjxKJFi4S/v7/OejIyMkTXrl2Fo6OjcHNzE1FRUWLdunXSeMi+fH9QyU++EUIIrVYrVq5cKVq2bCmUSqXw8fERsbGxIjs7Wwhx+wSd+Ph44e7uLjw8PMTkyZPFq6++KiIiIqRlyM+0pLrJ++rvv/8W06ZNE97e3kKlUolu3bqJAwcOVJunoKBAAJBOynkQnDx5UsTGxgofHx+hUqlEixYtxNtvvy2EEOLIkSMiMjJSODg4iLCwMLFx40YREhIiVqxYIc2fl5cnunfvLuzt7UWLFi1ERkZGjSff3O33zoEDB0T//v2Fi4uLcHZ2Fu3atROvvfaaEOL2iTg9e/YUjRo1Eo6OjqJdu3bS2dp11W+J+NgpKzFp0iT8+uuv2L17t7lLIdLb2LFjYWtri48//ljveXbv3o2+ffvi4sWLfC4rNQielXqfevPNN3Hs2DHk5+fj7bffxgcffIC4uDhzl0Wkl3/++QcnT57E3r178fDDD+s1j1qtxqVLl5CUlITHH3+coUgNhsF4nzpw4AD69++Ptm3bYu3atXjrrbfw9NNPm7ssIr3k5uYiMjISDz/8MJ577jm95vn0008REhKCoqIiLF26tIErpAcZD6USERHJcI+RiIhIhsFIREQkw2AkIiKSYTASERHJMBiJiIhkGIxEhKSkJLRv397cZRBZBAYjkZnEx8dDoVBUew0YMKBB16tQKPDNN9/otM2ePRtZWVkNul6i+wVvIk5kRgMGDEBqaqpOW9Ujrkyp6vl6RMQ9RiKzUqlU8Pf313k1atQIwO09u3fffRdDhgyBk5MTWrVqhb179yI/Px+9evWCs7MzunbtWu2xV2vWrJEe49SyZUt89NFH0riqh2KPHDkSCoVCGr7zUKpWq8WCBQsQFBQElUqF9u3bIyMjQxp/7tw5KBQKfP311+jduzecnJwQERGBvXv3NkxHEZkQg5HIgi1cuBATJkxATk4OwsPDMW7cODz77LOYM2cODh06BCEEnn/+eWn6TZs24YUXXsCsWbOQm5uLZ599FhMnTsSPP/4I4H/P7UxNTcWVK1eqPcezyqpVq7Bs2TK8+eabOH78OGJjYzFs2DCcPn1aZ7q5c+di9uzZyMnJQYsWLTB27Fj8888/DdQbRCZi1md7ED3A4uLihK2trXB2dtZ5VT3GB4D4z3/+I02/d+9eAUCsX79eavv000+Fg4ODNNy1a1cxadIknfU8/vjjYtCgQdIwanjc2Pz583UenRUYGCjVUaVTp05iypQpQoj/Pabo/fffl8afOHFCABCnTp0ysCeILAv3GInMqHfv3sjJydF5yW+q3a5dO+nnqqdJtG3bVqft1q1bKCkpAQCcOnUK3bp101lHt27dcOrUKb1rKikpweXLl/Vajry+qqfDFxYW6r0uIkvEk2+IzMjZ2RnNmzevdbxSqZR+VigUtbZptdoGqrBullQLkbFwj5HIirRq1Qp79uzRaduzZw9at24tDSuVSlRWVta6DDc3NwQGBt51OUTWinuMRGakVqtx9epVnTY7Ozt4e3vf0/JeeuklPPHEE+jQoQP69euH7777Dl9//TV27NghTRMaGoqsrCx069YNKpVKOgv2zuXMnz8fzZo1Q/v27ZGamoqcnBx88skn91QX0f2EwUhkRhkZGdJ3c1VatmyJX3/99Z6WN2LECKxatQpvvvkmXnjhBTRp0gSpqano1auXNM2yZcswc+ZMvPfee3jooYdw7ty5asuZPn06iouLMWvWLBQWFqJ169b473//i7CwsHuqi+h+wgcVExERyfA7RiIiIhkGIxERkQyDkYiISIbBSEREJMNgJCIikmEwEhERyTAYiYiIZBiMREREMgxGIiIiGQYjERGRDIORiIhI5v8D/omuWmoNVKMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "B_jGcireYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature engineering\n",
        "### Using Bag of Words\n",
        "Using scikit-learn ```CountVectorizer``` perform word frequency and use these as features to train a model.  \n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
      ],
      "metadata": {
        "id": "hgHvhTJuYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "rbl89LPUYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build analyzers (bag-of-words)\n",
        "BOW_vectorizer = CountVectorizer()"
      ],
      "metadata": {
        "id": "Bo8_GP6qYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
        "BOW_vectorizer.fit(train_df['text'])\n",
        "\n",
        "# 2. Transform documents to document-term matrix.\n",
        "train_data_BOW_features = BOW_vectorizer.transform(train_df['text'])\n",
        "test_data_BOW_features = BOW_vectorizer.transform(test_df['text'])"
      ],
      "metadata": {
        "id": "Bz_m0xn7YTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the result\n",
        "train_data_BOW_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cpCUVN8YTpo",
        "outputId": "c37dd1fd-cf26-42b0-97b6-298284a43dd7",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3613x10115 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 51467 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data_BOW_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "irGLsag-YTpo",
        "outputId": "dcad70ed-fc29-45be-c945-b46dec7d1f70",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._csr.csr_matrix"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>scipy.sparse._csr.csr_matrix</b><br/>def __init__(arg1, shape=None, dtype=None, copy=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/scipy/sparse/_csr.py</a>Compressed Sparse Row matrix.\n",
              "\n",
              "This can be instantiated in several ways:\n",
              "    csr_matrix(D)\n",
              "        where D is a 2-D ndarray\n",
              "\n",
              "    csr_matrix(S)\n",
              "        with another sparse array or matrix S (equivalent to S.tocsr())\n",
              "\n",
              "    csr_matrix((M, N), [dtype])\n",
              "        to construct an empty matrix with shape (M, N)\n",
              "        dtype is optional, defaulting to dtype=&#x27;d&#x27;.\n",
              "\n",
              "    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
              "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
              "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
              "\n",
              "    csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
              "        is the standard CSR representation where the column indices for\n",
              "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
              "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
              "        If the shape parameter is not supplied, the matrix dimensions\n",
              "        are inferred from the index arrays.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "dtype : dtype\n",
              "    Data type of the matrix\n",
              "shape : 2-tuple\n",
              "    Shape of the matrix\n",
              "ndim : int\n",
              "    Number of dimensions (this is always 2)\n",
              "nnz\n",
              "size\n",
              "data\n",
              "    CSR format data array of the matrix\n",
              "indices\n",
              "    CSR format index array of the matrix\n",
              "indptr\n",
              "    CSR format index pointer array of the matrix\n",
              "has_sorted_indices\n",
              "has_canonical_format\n",
              "T\n",
              "\n",
              "Notes\n",
              "-----\n",
              "\n",
              "Sparse matrices can be used in arithmetic operations: they support\n",
              "addition, subtraction, multiplication, division, and matrix power.\n",
              "\n",
              "Advantages of the CSR format\n",
              "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
              "  - efficient row slicing\n",
              "  - fast matrix vector products\n",
              "\n",
              "Disadvantages of the CSR format\n",
              "  - slow column slicing operations (consider CSC)\n",
              "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
              "\n",
              "Canonical Format\n",
              "    - Within each row, indices are sorted by column.\n",
              "    - There are no duplicate entries.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; from scipy.sparse import csr_matrix\n",
              "&gt;&gt;&gt; csr_matrix((3, 4), dtype=np.int8).toarray()\n",
              "array([[0, 0, 0, 0],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0]], dtype=int8)\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 0, 1, 2, 2, 2])\n",
              "&gt;&gt;&gt; col = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "&gt;&gt;&gt; indptr = np.array([0, 2, 3, 6])\n",
              "&gt;&gt;&gt; indices = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "Duplicate entries are summed together:\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 1, 2, 0])\n",
              "&gt;&gt;&gt; col = np.array([0, 1, 1, 0])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 4, 8])\n",
              "&gt;&gt;&gt; csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[9, 0, 0],\n",
              "       [0, 2, 0],\n",
              "       [0, 4, 0]])\n",
              "\n",
              "As an example of how to construct a CSR matrix incrementally,\n",
              "the following snippet builds a term-document matrix from texts:\n",
              "\n",
              "&gt;&gt;&gt; docs = [[&quot;hello&quot;, &quot;world&quot;, &quot;hello&quot;], [&quot;goodbye&quot;, &quot;cruel&quot;, &quot;world&quot;]]\n",
              "&gt;&gt;&gt; indptr = [0]\n",
              "&gt;&gt;&gt; indices = []\n",
              "&gt;&gt;&gt; data = []\n",
              "&gt;&gt;&gt; vocabulary = {}\n",
              "&gt;&gt;&gt; for d in docs:\n",
              "...     for term in d:\n",
              "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
              "...         indices.append(index)\n",
              "...         data.append(1)\n",
              "...     indptr.append(len(indices))\n",
              "...\n",
              "&gt;&gt;&gt; csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
              "array([[2, 1, 0, 0],\n",
              "       [0, 1, 1, 1]])</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 370);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add .toarray() to show\n",
        "train_data_BOW_features.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqbR8KWNYTpo",
        "outputId": "4239cf8b-7942-4c7b-bf17-46a11d7eeebc",
        "scrolled": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension\n",
        "train_data_BOW_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL0xkGyGYTpo",
        "outputId": "4f750483-f83c-4432-c37c-ea998f602792",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3613, 10115)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# observe some feature names\n",
        "feature_names = BOW_vectorizer.get_feature_names_out()\n",
        "feature_names[100:110]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyRaxyBZYTpo",
        "outputId": "c99a1dc0-20d7-4244-ae12-a5f44ed77574",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2k17', '2much', '2nd', '30', '300', '301', '30am', '30pm', '30s',\n",
              "       '31'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zm00p_sxYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedding is done. We can technically feed this into our model. However, depending on the embedding technique you use and your model, your accuracy might not be as high, because:\n",
        "\n",
        "* curse of dimensionality  (we have 10,115 dimension now)\n",
        "* some important features are ignored (for example, some models using emoticons yeld better performance than counterparts)"
      ],
      "metadata": {
        "id": "roSfgQKaYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\" in feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx4YPbrdYTpo",
        "outputId": "3bec7501-4d93-4e72-b746-efb63a3bb925",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try using another tokenizer below."
      ],
      "metadata": {
        "id": "0MFzyA95YTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "# build analyzers (bag-of-words)\n",
        "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize)\n",
        "\n",
        "# apply analyzer to training data\n",
        "BOW_500.fit(train_df['text'])\n",
        "\n",
        "train_data_BOW_features_500 = BOW_500.transform(train_df['text'])\n",
        "\n",
        "## check dimension\n",
        "train_data_BOW_features_500.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SttodxACYTpo",
        "outputId": "37a72941-1bcb-47a6-8940-ff0c641c3fbf",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3613, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_BOW_features_500.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPi42W0pYTpo",
        "outputId": "093fd99b-c1d1-46b3-d7f4-56fa125a84f8",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 2, 0, ..., 0, 0, 0],\n",
              "       [0, 2, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 2, 1, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# observe some feature names\n",
        "feature_names_500 = BOW_500.get_feature_names_out()\n",
        "feature_names_500[100:110]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCgAnTOfYTpo",
        "outputId": "020e924b-eed0-4af5-d7ec-3cccd614abdd",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['change', 'cheer', 'cheerful', 'cheering', 'cheery', 'come',\n",
              "       'comes', 'could', 'country', 'cry'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\" in feature_names_500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubgedNi4YTpo",
        "outputId": "f41b0ae9-1694-4e48-b9f9-885b2b431c66",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ** >>> Exercise 2 (Take home): **  \n",
        "Generate an embedding using the TF-IDF vectorizer instead of th BOW one with 1000 features and show the feature names for features [100:110]."
      ],
      "metadata": {
        "id": "fj6TV4ngYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create a TF-IDF vectorizer with a maximum of 1000 features\n",
        "TFIDF_vectorizer = TfidfVectorizer(max_features=1000, tokenizer=nltk.word_tokenize)\n",
        "\n",
        "# generate TF-IDF features for the train dataset\n",
        "TFIDF_vectorizer.fit(train_df['text'])\n",
        "\n",
        "# Transform train and test datasets into TF-IDF feature matrices\n",
        "train_data_TFIDF_features = TFIDF_vectorizer.transform(train_df['text'])\n",
        "test_data_TFIDF_features = TFIDF_vectorizer.transform(test_df['text'])\n",
        "\n",
        "# Extract feature names\n",
        "feature_names_TFIDF = TFIDF_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print feature names in [100:110]\n",
        "print(\"Feature names [100:110]:\", feature_names_TFIDF[100:110])"
      ],
      "metadata": {
        "id": "BOjVbgmxYTpo",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0da2d6-c3f6-4673-a410-6a2dde956e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names [100:110]: ['attacks' 'awareness' 'away' 'awe' 'awesome' 'awful' 'b' 'baby' 'back'\n",
            " 'bad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. Model\n",
        "### 3.1 Decision Trees\n",
        "Using scikit-learn ```DecisionTreeClassifier``` performs word frequency and uses these as features to train a model.  \n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "e0BvbNAVYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# for a classificaiton problem, you need to provide both training & testing data\n",
        "X_train = BOW_500.transform(train_df['text'])\n",
        "y_train = train_df['emotion']\n",
        "\n",
        "X_test = BOW_500.transform(test_df['text'])\n",
        "y_test = test_df['emotion']\n",
        "\n",
        "## take a look at data dimension is a good habit  :)\n",
        "print('X_train.shape: ', X_train.shape)\n",
        "print('y_train.shape: ', y_train.shape)\n",
        "print('X_test.shape: ', X_test.shape)\n",
        "print('y_test.shape: ', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD0rMWKgYTpo",
        "outputId": "0a23f4cb-0eb4-4db8-fba3-b9eddb78ee08",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape:  (3613, 500)\n",
            "y_train.shape:  (3613,)\n",
            "X_test.shape:  (347, 500)\n",
            "y_test.shape:  (347,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## build DecisionTree model\n",
        "DT_model = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "## training!\n",
        "DT_model = DT_model.fit(X_train, y_train)\n",
        "\n",
        "## predict!\n",
        "y_train_pred = DT_model.predict(X_train)\n",
        "y_test_pred = DT_model.predict(X_test)\n",
        "\n",
        "## so we get the pred result\n",
        "y_test_pred[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDuvLf7TYTpo",
        "outputId": "890c5e4d-d0c2-4b99-a865-d8b6c6b82e8b",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['fear', 'fear', 'fear', 'joy', 'anger', 'anger', 'joy', 'anger',\n",
              "       'joy', 'anger'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zqZHlDjxYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. Results Evaluation"
      ],
      "metadata": {
        "id": "iBNmBT50YTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will check the results of our model's performance"
      ],
      "metadata": {
        "id": "-gQU_PbhYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
        "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
        "\n",
        "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
        "print('testing accuracy: {}'.format(round(acc_test, 2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9yx3tv-YTpo",
        "outputId": "afdd72c9-2c45-4f5a-fa99-08998e2287f1",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: 0.99\n",
            "testing accuracy: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## precision, recall, f1-score,\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wkOqjqiYTpo",
        "outputId": "14496c7c-2cab-4181-a159-31b7caa1a8db",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.62      0.71      0.67        84\n",
            "        fear       0.67      0.63      0.65       110\n",
            "         joy       0.74      0.67      0.70        79\n",
            "     sadness       0.62      0.64      0.63        74\n",
            "\n",
            "    accuracy                           0.66       347\n",
            "   macro avg       0.66      0.66      0.66       347\n",
            "weighted avg       0.66      0.66      0.66       347\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## check by confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6mhrmKHYTpo",
        "outputId": "6df26e73-a63f-4161-e2df-90819d97961f",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[60 11  7  6]\n",
            " [20 69  7 14]\n",
            " [ 6 11 53  9]\n",
            " [10 12  5 47]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciton for visualizing confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
        "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
        "    \"\"\"\n",
        "    This function is modified from:\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \"\"\"\n",
        "    classes.sort()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels = classes,\n",
        "           yticklabels = classes,\n",
        "           title = title,\n",
        "           xlabel = 'Predicted label',\n",
        "           ylabel = 'True label')\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    ylim_top = len(classes) - 0.5\n",
        "    plt.ylim([ylim_top, -.5])\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-TcX8NA5YTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot your confusion matrix\n",
        "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
        "plot_confusion_matrix(cm, classes=my_tags, title='Confusion matrix')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "1nBVOUpDYTpo",
        "outputId": "2bfbf9b7-dd6b-48ad-e81c-c08aaea06aab",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ** >>> Exercise 3 (Take home): **  \n",
        "Can you interpret the results above? What do they mean?"
      ],
      "metadata": {
        "id": "l743vmwgYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The numbers in cnfusion matrix means the amount of time it's been predict as. If true equals to predicted, wich means the prediction is correct. So in the graphic above we can see the result in the diagnal valume is high, wich means the prediction is nice. However there's still some error exist. Worth noticing that feat and anger seems to share some relation where their error count between each other is higher then others"
      ],
      "metadata": {
        "id": "YGFjJinGVHX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ** >>> Exercise 4 (Take home): **  \n",
        "Build a model using a ```Naive Bayes``` model and train it. What are the testing results?\n",
        "\n",
        "*Reference*: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
      ],
      "metadata": {
        "id": "GaHpgl87YTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "# Train the Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "# Predictions for training and testing sets\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracies\n",
        "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
        "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
        "\n",
        "# Display accuracies\n",
        "print('Training accuracy: {}'.format(round(acc_train, 2)))\n",
        "print('Testing accuracy: {}'.format(round(acc_test, 2)))\n",
        "\n",
        "# Compute confusion matrix for the testing set\n",
        "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred, labels=['anger', 'fear', 'joy', 'sadness'])\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Plot confusion matrix\n",
        "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
        "plot_confusion_matrix(cm, classes=my_tags, title='Confusion Matrix for Naive Bayes Model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "L9m0zN3NV9iA",
        "outputId": "f25c98be-02d8-4219-cd99-f0e16471ef7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MultinomialNB' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-67f2f672a9ac>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Train the Naive Bayes model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Predictions for training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MultinomialNB' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ** >>> Exercise 5 (Take home): **  \n",
        "\n",
        "How do the results from the Naive Bayes model and the Decision Tree model compare? How do you interpret these differences? Use the theoretical background covered in class to try and explain these differences."
      ],
      "metadata": {
        "id": "Xv2DqWQSYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's result is pretty much the same, but in Naive Bayes the number of correctcount in 'fear' increase. Other emotions show some misclassifications, but errors are pretty close to the Decision Tree.\n",
        "\n",
        "Naive Bayes capture probabilistic relationships in sparse data efficiently. Which means it has effective when the feature space is large and the dataset is sparse. ex.text data"
      ],
      "metadata": {
        "id": "4A3cyRtVVVvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ehlJ60lhYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Other things you can try"
      ],
      "metadata": {
        "id": "79F_DaW-YTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, there are several things you can try that will affect your results. In order to yield better results, you can experiment by:\n",
        "- Trying different features (Feature engineering)e.g Word2Vec, PCA, LDA, FastText, Clustering\n",
        "- Trying different models\n",
        "- Analyzing your results and interpret them to improve your feature engineering/model building process\n",
        "- Iterate through the steps above until finding a satisfying result\n",
        "\n",
        "Remember that you should also consider the task at hand and the model you'll feed the data to."
      ],
      "metadata": {
        "id": "_oeqpRu6YTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. Deep Learning\n",
        "\n",
        "We use [Keras](https://keras.io/) to be our deep learning framework, and follow the [Model (functional API)](https://keras.io/models/model/) to build a Deep Neural Network (DNN) model. Keras runs with Tensorflow in the backend. It's a nice abstraction to start working with NN models.\n",
        "\n",
        "Because Deep Learning is a 1-semester course, we can't talk about each detail about it in the lab session. Here, we only provide a simple template about how to build & run a DL model successfully. You can follow this template to design your model.\n",
        "\n",
        "We will begin by building a fully connected network, which looks like this:"
      ],
      "metadata": {
        "id": "fiGUSmPLYTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![pic1.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic1.png?raw=true)\n",
        "\n",
        "(source: https://github.com/drewnoff/spark-notebook-ml-labs/tree/master/labs/DLFramework)\n"
      ],
      "metadata": {
        "id": "1nB0BTq2YTpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Prepare data (X, y)"
      ],
      "metadata": {
        "id": "-EtVRGhNYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "# standardize name (X, y)\n",
        "X_train = BOW_500.transform(train_df['text'])\n",
        "y_train = train_df['emotion']\n",
        "\n",
        "X_test = BOW_500.transform(test_df['text'])\n",
        "y_test = test_df['emotion']\n",
        "\n",
        "## check dimension is a good habbit\n",
        "print('X_train.shape: ', X_train.shape)\n",
        "print('y_train.shape: ', y_train.shape)\n",
        "print('X_test.shape: ', X_test.shape)\n",
        "print('y_test.shape: ', y_test.shape)"
      ],
      "metadata": {
        "id": "4mIdg2D6YTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "trusted": true,
        "id": "kG7Pe2R_T2bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOW_500.transform(test_df['text'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "DRyVRLQRT2bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Deal with categorical label (y)\n",
        "\n",
        "Rather than put your label `train_df['emotion']` directly into a model, we have to process these categorical (or say nominal) label by ourselves.\n",
        "\n",
        "Here, we use the basic method [one-hot encoding](https://en.wikipedia.org/wiki/One-hot) to transform our categorical  labels to numerical ones.\n"
      ],
      "metadata": {
        "id": "iBZZedZ2YTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## deal with label (string -> one-hot)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "print('check label: ', label_encoder.classes_)\n",
        "print('\\n## Before convert')\n",
        "print('y_train[0:4]:\\n', y_train[0:4])\n",
        "print('\\ny_train.shape: ', y_train.shape)\n",
        "print('y_test.shape: ', y_test.shape)\n",
        "\n",
        "def label_encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def label_decode(le, one_hot_label):\n",
        "    dec = np.argmax(one_hot_label, axis=1)\n",
        "    return le.inverse_transform(dec)\n",
        "\n",
        "y_train = label_encode(label_encoder, y_train)\n",
        "y_test = label_encode(label_encoder, y_test)\n",
        "\n",
        "print('\\n\\n## After convert')\n",
        "print('y_train[0:4]:\\n', y_train[0:4])\n",
        "print('\\ny_train.shape: ', y_train.shape)\n",
        "print('y_test.shape: ', y_test.shape)\n"
      ],
      "metadata": {
        "id": "SU95MCsSYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 Build model"
      ],
      "metadata": {
        "id": "W4bqEcMbYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I/O check\n",
        "input_shape = X_train.shape[1]\n",
        "print('input_shape: ', input_shape)\n",
        "\n",
        "output_shape = len(label_encoder.classes_)\n",
        "print('output_shape: ', output_shape)"
      ],
      "metadata": {
        "id": "6sA7cx-oYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![pic2.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic2.png?raw=true)"
      ],
      "metadata": {
        "id": "8c-uWuloYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import ReLU, Softmax\n",
        "\n",
        "# input layer\n",
        "model_input = Input(shape=(input_shape, ))  # 500\n",
        "X = model_input\n",
        "\n",
        "# 1st hidden layer\n",
        "X_W1 = Dense(units=64)(X)  # 64\n",
        "H1 = ReLU()(X_W1)\n",
        "\n",
        "# 2nd hidden layer\n",
        "H1_W2 = Dense(units=64)(H1)  # 64\n",
        "H2 = ReLU()(H1_W2)\n",
        "\n",
        "# output layer\n",
        "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
        "H3 = Softmax()(H2_W3)\n",
        "\n",
        "model_output = H3\n",
        "\n",
        "# create model\n",
        "model = Model(inputs=[model_input], outputs=[model_output])\n",
        "\n",
        "# loss function & optimizer\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# show model construction\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jTeBWTvgYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 Train"
      ],
      "metadata": {
        "id": "nmTSDO2pYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "csv_logger = CSVLogger('training_log.csv')\n",
        "\n",
        "# training setting\n",
        "epochs = 25\n",
        "batch_size = 32\n",
        "\n",
        "# training!\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[csv_logger],\n",
        "                    validation_data = (X_test, y_test))\n",
        "print('training finish')"
      ],
      "metadata": {
        "id": "Kl374LYqYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.5 Predict on testing data"
      ],
      "metadata": {
        "id": "ip8RYsvSYTpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## predict\n",
        "pred_result = model.predict(X_test, batch_size=128)\n",
        "pred_result[:5]"
      ],
      "metadata": {
        "id": "xdnLuBYBYTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_result = label_decode(label_encoder, pred_result)\n",
        "pred_result[:5]"
      ],
      "metadata": {
        "id": "hSaXGEX-YTpo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), pred_result), 2)))"
      ],
      "metadata": {
        "id": "bRRHye9KYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's take a look at the training log\n",
        "training_log = pd.DataFrame()\n",
        "training_log = pd.read_csv(\"training_log.csv\")\n",
        "training_log"
      ],
      "metadata": {
        "id": "ks2Q0aMsYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ** >>> Exercise 6 (Take home): **  \n",
        "\n",
        "Plot the Training and Validation Accuracy and Loss (different plots), just like the images below.(Note: the pictures below are an example from a different model). How to interpret the graphs you got? How are they related to the concept of overfitting/underfitting covered in class?!\n",
        "\n",
        "<table><tr>\n",
        "    <td><img src=\"https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic3.png?raw=true\" style=\"width: 300px;\"/> </td>\n",
        "    <td><img src=\"https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic4.png?raw=true\" style=\"width: 300px;\"/> </td>\n",
        "</tr></table>"
      ],
      "metadata": {
        "id": "NoYqY0-tYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training log\n",
        "training_log = pd.read_csv(\"training_log.csv\")\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(training_log['epoch'], training_log['accuracy'], label='Train accuracy', color='blue')\n",
        "plt.plot(training_log['epoch'], training_log['val_accuracy'], label='Val accuracy', color='red')\n",
        "plt.title('Training Accuracy per Epoch')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(training_log['epoch'], training_log['loss'], label='Train loss', color='blue')\n",
        "plt.plot(training_log['epoch'], training_log['val_loss'], label='Val loss', color='red')\n",
        "plt.title('Training Loss per Epoch')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AlhstCrlYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "UYabzgSGYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note\n",
        "\n",
        "If you don't have a GPU (level is higher than GTX 1060) or you are not good at setting lots of things about computer, we recommend you to use the [kaggle kernel](https://www.kaggle.com/kernels) to do deep learning model training. They have already installed all the librarys and provided free GPU for you to use.\n",
        "\n",
        "Note however that you will only be able to run a kernel for 6 hours. After 6 hours of inactivity, your Kaggle kernel will shut down (meaning if your model takes more than 6 hours to train, you can't train it at once).\n",
        "\n",
        "\n",
        "### More Information for your reference\n",
        "\n",
        "* Keras document: https://keras.io/\n",
        "* Keras GitHub example: https://github.com/keras-team/keras/tree/master/examples\n",
        "* CS229: Machine Learning: http://cs229.stanford.edu/syllabus.html\n",
        "* Deep Learning cheatsheet: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning\n",
        "* If you want to try TensorFlow or PyTorch: https://pytorch.org/tutorials/\n",
        "https://www.tensorflow.org/tutorials/quickstart/beginner"
      ],
      "metadata": {
        "id": "4e5eiVLOYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7. Word2Vector\n",
        "\n",
        "We will introduce how to use `gensim` to train your word2vec model and how to load a pre-trained model.\n",
        "\n",
        "https://radimrehurek.com/gensim/index.html"
      ],
      "metadata": {
        "id": "IESBq48MYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Prepare training corpus"
      ],
      "metadata": {
        "id": "KRSDMhQ5YTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## check library\n",
        "import gensim\n",
        "\n",
        "## ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# # if you want to see the training messages, you can use it\n",
        "# import logging\n",
        "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "## the input type\n",
        "train_df['text_tokenized'] = train_df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
        "train_df[['id', 'text', 'text_tokenized']].head()"
      ],
      "metadata": {
        "id": "6aBYrovJYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create the training corpus\n",
        "training_corpus = train_df['text_tokenized'].values\n",
        "training_corpus[:3]"
      ],
      "metadata": {
        "id": "okFIEcmnYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Training our model\n",
        "\n",
        "You can try to train your own model. More details: https://radimrehurek.com/gensim/models/word2vec.html"
      ],
      "metadata": {
        "id": "dOgAriPRYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "## setting\n",
        "vector_dim = 100\n",
        "window_size = 5\n",
        "min_count = 1\n",
        "training_epochs = 20\n",
        "\n",
        "## model\n",
        "word2vec_model = Word2Vec(sentences=training_corpus,\n",
        "                          vector_size=vector_dim, window=window_size,\n",
        "                          min_count=min_count, epochs=training_epochs)"
      ],
      "metadata": {
        "id": "72ZA54IDYTp5",
        "scrolled": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Imgur](https://i.imgur.com/Fca3MCs.png)"
      ],
      "metadata": {
        "id": "ob0Molb3YTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Generating word vector (embeddings)"
      ],
      "metadata": {
        "id": "E0jjvjN5YTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the corresponding vector of a word\n",
        "word_vec = word2vec_model.wv['happy']\n",
        "word_vec"
      ],
      "metadata": {
        "id": "4ejofZfCYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the most similar words\n",
        "word = 'happy'\n",
        "topn = 10\n",
        "word2vec_model.wv.most_similar(word, topn=topn)"
      ],
      "metadata": {
        "id": "9dUSkCscYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Using a pre-trained w2v model\n",
        "\n",
        "Instead of training your own model ,you can use a model that has already been trained. Here, we see 2 ways of doing that:\n",
        "\n",
        "\n",
        "#### (1) Download model by yourself\n",
        "\n",
        "source: [GoogleNews-vectors-negative300](https://code.google.com/archive/p/word2vec/)\n",
        "\n",
        "more details: https://radimrehurek.com/gensim/models/keyedvectors.html"
      ],
      "metadata": {
        "id": "zuQvZVJvYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "## Note: this model is very huge, this will take some time ...\n",
        "model_path = f\"{didiersalazar_google_news_vectors_path}/GoogleNews-vectors-negative300.bin\"\n",
        "w2v_google_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
        "print('load ok')\n",
        "\n",
        "w2v_google_model.most_similar('happy', topn=10)"
      ],
      "metadata": {
        "id": "bdH9E9auYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) Using gensim api\n",
        "\n",
        "Other pretrained models are available here: https://github.com/RaRe-Technologies/gensim-data"
      ],
      "metadata": {
        "id": "NdQ9ul0eYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "## If you see `SSL: CERTIFICATE_VERIFY_FAILED` error, use this:\n",
        "import ssl\n",
        "import urllib.request\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "glove_twitter_25_model = api.load(\"glove-twitter-25\")\n",
        "print('load ok')\n",
        "\n",
        "glove_twitter_25_model.most_similar('happy', topn=10)"
      ],
      "metadata": {
        "id": "oIxHpNB6YTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5 king + woman - man = ?"
      ],
      "metadata": {
        "id": "GCNDNqeXYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run one of the most famous examples for Word2Vec and compute the similarity between these 3 words:"
      ],
      "metadata": {
        "id": "_GtCRr_7YTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_google_model.most_similar(positive=['king', 'woman'], negative=['man'])"
      ],
      "metadata": {
        "id": "Zew7m_kIYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ** >>> Exercise 7 (Take home): **  \n",
        "\n",
        "Now, we have the word vectors, but our input data is a sequence of words (or say sentence).\n",
        "How can we utilize these \"word\" vectors to represent the sentence data and train our model?\n"
      ],
      "metadata": {
        "id": "y3RQVnBOYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can try to utilize the approach such as embedding."
      ],
      "metadata": {
        "id": "7w9daR4jWxn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Clustering: k-means\n",
        "\n",
        "Here we introduce how to use `sklearn` to do the basic **unsupervised learning** approach, k-means.    \n",
        "\n",
        "more details: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n"
      ],
      "metadata": {
        "id": "LrK7O1KDYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basic concept\n",
        "\n",
        "![Image](https://i.imgur.com/PEdUf54.png)\n",
        "\n",
        "(img source: https://towardsdatascience.com/k-means-clustering-identifying-f-r-i-e-n-d-s-in-the-world-of-strangers-695537505d)"
      ],
      "metadata": {
        "id": "Hr8_IxwBYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clustering target\n",
        "target_list = ['happy', 'fear', 'angry', 'car', 'teacher', 'computer']\n",
        "print('target words: ', target_list)\n",
        "\n",
        "# convert to word vector\n",
        "X = [word2vec_model.wv[word] for word in target_list]"
      ],
      "metadata": {
        "id": "6heUPVwWYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# we have to decide how many cluster (k) we want\n",
        "k = 2\n",
        "\n",
        "# k-means model\n",
        "kmeans_model = KMeans(n_clusters=k)\n",
        "kmeans_model.fit(X)\n",
        "\n",
        "# cluster result\n",
        "cluster_result = kmeans_model.labels_\n",
        "\n",
        "# show\n",
        "for i in range(len(target_list)):\n",
        "    print('word: {} \\t cluster: {}'.format(target_list[i], cluster_result[i]))"
      ],
      "metadata": {
        "id": "E9t_sJrvYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![pic6.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic6.png?raw=true)"
      ],
      "metadata": {
        "id": "QcDTL7kRYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check cluster membership\n",
        "word = 'student'\n",
        "word_vec = word2vec_model.wv[word]\n",
        "kmeans_model.predict([word_vec])"
      ],
      "metadata": {
        "id": "NIMFax_uYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check cluster membership\n",
        "word = 'sad'\n",
        "word_vec = word2vec_model.wv[word]\n",
        "kmeans_model.predict([word_vec])"
      ],
      "metadata": {
        "id": "vIDuLDOlYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 9. High-dimension Visualization: t-SNE and UMAP\n",
        "\n",
        "No matter if you use the Bag-of-words, TF-IDF, or Word2Vec, it's very hard to see the embedding result, because the dimension is larger than 3.  \n",
        "\n",
        "In Lab 1, we already talked about PCA, t-SNE and UMAP. We can use PCA to reduce the dimension of our data, then visualize it. However, if you dig deeper into the result, you'd find it is insufficient.\n",
        "\n",
        "Our aim will be to create a visualization similar to the one below with t-SNE:"
      ],
      "metadata": {
        "id": "cZOEGH3GYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  "
      ],
      "metadata": {
        "id": "4FeIFzzxYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![pic7.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic7.png?raw=true)\n",
        "source: https://www.fabian-keller.de/research/high-dimensional-data-visualization"
      ],
      "metadata": {
        "id": "3-JR-rqyYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And also like this for UMAP:\n",
        "\n",
        "![pic9.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic9.png?raw=true)\n",
        "\n",
        "source: https://umap-learn.readthedocs.io/en/latest/auto_examples/plot_mnist_example.html"
      ],
      "metadata": {
        "id": "yI4ctIEyT2bF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  "
      ],
      "metadata": {
        "id": "KCFR771SYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "t-SNE and UMAP reference:  \n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
        "https://umap-learn.readthedocs.io/en/latest/"
      ],
      "metadata": {
        "id": "tmdbJbjxYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1 Prepare visualizing target"
      ],
      "metadata": {
        "id": "MU8eeDnGYTp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's prepare data lists like:\n",
        "- happy words\n",
        "- angry words\n",
        "- data words\n",
        "- mining words"
      ],
      "metadata": {
        "id": "T9IHcP3VYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = ['happy', 'angry', 'data', 'mining']\n",
        "\n",
        "topn = 5\n",
        "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]\n",
        "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]\n",
        "data_words = ['data'] + [word_ for word_, sim_ in w2v_google_model.most_similar('data', topn=topn)]\n",
        "mining_words = ['mining'] + [word_ for word_, sim_ in w2v_google_model.most_similar('mining', topn=topn)]\n",
        "\n",
        "print('happy_words: ', happy_words)\n",
        "print('angry_words: ', angry_words)\n",
        "print('data_words: ', data_words)\n",
        "print('mining_words: ', mining_words)\n",
        "\n",
        "target_words = happy_words + angry_words + data_words + mining_words\n",
        "print('\\ntarget words: ')\n",
        "print(target_words)\n",
        "\n",
        "print('\\ncolor list:')\n",
        "cn = topn + 1\n",
        "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
        "print(color)"
      ],
      "metadata": {
        "id": "L9il5L7pYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2 Plot using t-SNE and UMAP (2-dimension)"
      ],
      "metadata": {
        "id": "zKa5LRxbYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "## w2v model\n",
        "model = w2v_google_model\n",
        "\n",
        "## prepare training word vectors\n",
        "size = 200\n",
        "target_size = len(target_words)\n",
        "all_word = list(model.index_to_key)\n",
        "word_train = target_words + all_word[:size]\n",
        "X_train = model[word_train]\n",
        "\n",
        "## t-SNE model\n",
        "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
        "\n",
        "## training\n",
        "X_tsne = tsne.fit_transform(X_train)\n",
        "\n",
        "## plot the result\n",
        "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
        "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
        "for label, x, y in zip(target_words, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
        "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CJlljN2gYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import umap.umap_ as umap\n",
        "\n",
        "## w2v model\n",
        "model = w2v_google_model\n",
        "\n",
        "## prepare training word vectors\n",
        "size = 200\n",
        "target_size = len(target_words)\n",
        "all_word = list(model.index_to_key)\n",
        "word_train = target_words + all_word[:size]\n",
        "X_train = model[word_train]\n",
        "\n",
        "## UMAP model\n",
        "umap_model = umap.UMAP(n_components=2, metric='cosine', random_state=28)\n",
        "\n",
        "## training\n",
        "X_umap = umap_model.fit_transform(X_train)\n",
        "\n",
        "## plot the result\n",
        "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
        "plt.scatter(X_umap[:target_size, 0], X_umap[:target_size, 1], c=color)\n",
        "for label, x, y in zip(target_words, X_umap[:target_size, 0], X_umap[:target_size, 1]):\n",
        "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "HYK8pvkcT2bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ** >>> Exercise 8 (Take home): **  \n",
        "\n",
        "Generate a t-SNE and UMAP visualization to show the 15 words most related to the words \"angry\", \"happy\", \"sad\", \"fear\" (60 words total). Compare the differences between both graphs."
      ],
      "metadata": {
        "id": "2PL61rqYYTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import umap.umap_ as umap\n",
        "\n",
        "# Define the target words\n",
        "word_list = ['angry', 'happy', 'sad', 'fear']\n",
        "topn = 15\n",
        "target_words = []\n",
        "\n",
        "# Retrieve the most similar words for each target word\n",
        "for word in word_list:\n",
        "    similar_words = [word] + [w for w, _ in w2v_google_model.most_similar(word, topn=topn)]\n",
        "    target_words.extend(similar_words)\n",
        "\n",
        "# Assign colors to words based on their group\n",
        "color_map = ['r'] * (topn + 1) + ['b'] * (topn + 1) + ['g'] * (topn + 1) + ['y'] * (topn + 1)\n",
        "\n",
        "# Extract word vectors\n",
        "word_vectors = w2v_google_model[target_words]\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne_model = TSNE(n_components=2, metric='cosine', random_state=42)\n",
        "X_tsne = tsne_model.fit_transform(word_vectors)\n",
        "\n",
        "# Perform UMAP\n",
        "umap_model = umap.UMAP(n_components=2, metric='cosine', random_state=42)\n",
        "X_umap = umap_model.fit_transform(word_vectors)\n",
        "\n",
        "# Plot t-SNE result\n",
        "plt.figure(figsize=(8, 8), dpi=120)\n",
        "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=color_map)\n",
        "for label, x, y in zip(target_words, X_tsne[:, 0], X_tsne[:, 1]):\n",
        "    plt.annotate(label, (x, y), fontsize=8, alpha=0.75)\n",
        "plt.title(\"t-SNE Visualization\")\n",
        "plt.show()\n",
        "\n",
        "# Plot UMAP result\n",
        "plt.figure(figsize=(8, 8), dpi=120)\n",
        "plt.scatter(X_umap[:, 0], X_umap[:, 1], c=color_map)\n",
        "for label, x, y in zip(target_words, X_umap[:, 0], X_umap[:, 1]):\n",
        "    plt.annotate(label, (x, y), fontsize=8, alpha=0.75)\n",
        "plt.title(\"UMAP Visualization\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rvh7ymeNYTp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Large Language Models (LLMs)\n",
        "Large Language Models (LLMs) are AI models trained on vast text data to understand and generate human language. Models like GPT and BERT excel at tasks like translation, summarization, and sentiment analysis due to their deep learning techniques and large-scale training. Recently these models got popular with the rise of Open-AI's ChatGPT and their different models, showcasing the potential of these models in a lot of aspects of our current society.\n",
        "\n",
        "Open-source LLMs are cost-effective and customizable, with strong community support, but may underperform compared to paid models and require technical expertise to manage. Paid LLMs offer superior performance, ease of use, and regular updates, but are costly, less flexible, and create dependency on external providers for ongoing access and updates.\n",
        "\n",
        "#### Open Source LLMs:\n",
        "In this lab we are going to use Ollama ([Ollama GitHub Link](https://github.com/ollama/ollama)), that is a library that let us use a long list of open-source LLMs of differing size. For this section we are going to be using **'llama3.2'** or **'llama3.2:1b'** for **text based tasks**, and **'llava-phi3'** for **multi-modal tasks** (e.g. image to text). Ollama has a great variety of models, and those can be found here: [model library](https://ollama.com/library). You are free to explore them if you want to try using them, you can check the advantages and disadvantages of each.\n",
        "\n",
        "Or they can also be observed in here:\n",
        "\n",
        "![pic10.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic10.png?raw=true)\n",
        "\n",
        "\n",
        "In the previous image we can observe that all LLMs have something called parameters, these are the internal weights that the model learns during training, helping it understand and generate language. The more a model has, the more complex and accurate it can be, but it also needs more memory to run.\n",
        "\n",
        "For example:\n",
        "\n",
        "Models with **7 billion parameters** need at least **8 GB of VRAM**.\n",
        "**13 billion parameters** require **16 GB of VRAM**.\n",
        "**33 billion parameters** need **32 GB of VRAM**.\n",
        "The higher the number of parameters, the more memory and computational power the model needs to function efficiently.\n",
        "\n",
        "And so that is why we are trying to use small LLMs for this practice, because they require a lot of computational resources, so by using 'llama3.2' and 'llava-phi3', both models with 3 billion parameters, we will only use at most 8 GB of VRAM. But if there are some issues with 'llama3.2' we can still use 'llama3.2:1b' the model with 1 billion parameters that requires less resources.\n",
        "\n",
        "So now let's talk about the models:\n",
        "**LLaMA 3.2** is part of the LLaMA series (Large Language Model Meta AI), designed to provide efficient language understanding and generation. Despite having fewer parameters than some larger models, it offers strong performance in NLP tasks, making it suitable for scenarios where both accuracy and resource efficiency are important.\n",
        "\n",
        "**LLaVA** (Large Language and Vision Assistant) models, like **LLaVA-Phi3** are multimodal models combining language and vision capabilities. It can interpret visual inputs like images and generate corresponding text, making it ideal for tasks that require both visual understanding and language generation, such as image captioning and answering visual-based questions.\n",
        "\n",
        "**I will be using the llama3.2 model going onwards, you can change it for the smallest version if it is necessary for you, or you can try to run it on Kaggle where you can use online GPU resources for it.**"
      ],
      "metadata": {
        "id": "rsgZGICyT2bG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.1 Text Prompting\n",
        "Like with ChatGPT we can use these models to ask about anything. Here we are going to ask a question and then ask it to return it in markdown format to make it look better afterwards."
      ],
      "metadata": {
        "id": "iobuTgpvT2bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "response = ollama.chat(model='llama3.2', messages=[\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': 'What is data mining? (in markdown format)'\n",
        "    },\n",
        "])\n",
        "\n",
        "print(response['message']['content'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "xGdLUfnLT2bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can use the IPython library to make the response look better:**"
      ],
      "metadata": {
        "id": "xfSZ3xZ6T2bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, Latex\n",
        "display(Markdown('*some markdown* $\\phi$'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "siSxBHTnT2bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response['message']['content']))"
      ],
      "metadata": {
        "trusted": true,
        "id": "_gaoYg5kT2bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ** >>> Exercise 9 (Take home): **  \n",
        "\n",
        "You noticed there is a **role** parameter inside the ollama.chat function, investigate what other roles there can be inside the function and what do they do. Give an example of a prompt using another role in additional to the **user** one."
      ],
      "metadata": {
        "id": "S7_0_dnbT2bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. user: Represents input from the user, typically a question, statement, or command.\n",
        "2. assistant: Represents the model's response or reply to the user.\n",
        "3. system: Sets the behavior, tone, or instructions for the assistant. This role is often used to configure the assistant's personality or purpose."
      ],
      "metadata": {
        "id": "SyWwKtYSYTls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "\n",
        "response = ollama.chat(model='llama3.2', messages=[\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': 'You are a data science tutor. Provide explanations suitable for a beginner audience.'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': 'What is data mining? (in markdown format)'\n",
        "    }\n",
        "])\n",
        "\n",
        "print(response['message']['content'])"
      ],
      "metadata": {
        "id": "EhfvNcomYaSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2 Multi-Modal Prompting - Text + Images\n",
        "Multi-modal prompting involves using input from multiple sources or modes, such as text, images, or audio, to guide a model's response. It allows AI to process and generate information based on more than one type of input.\n",
        "\n",
        "For image plus text prompting, the model receives both an image and a related text prompt. The image provides visual context, while the text gives additional guidance. The model uses both inputs to generate more accurate and contextually relevant responses, which is useful for tasks like image captioning, visual question answering, or content generation based on visual cues."
      ],
      "metadata": {
        "id": "_bpxZgheT2bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the following images that are in the **pics** folder in the directory of this notebook:"
      ],
      "metadata": {
        "id": "f4TgTPn0T2bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![example1.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/example1.png?raw=true)\n",
        "\n",
        "source: https://cooljapan-videos.com/tw/articles/epe0y86g"
      ],
      "metadata": {
        "id": "RrDFcpFLjV4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![example2.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/example2.jpg?raw=true)\n",
        "\n",
        "source: https://www.istockphoto.com/photo/young-cat-scottish-straight-gm1098182434-294927481"
      ],
      "metadata": {
        "id": "LFnDDhB8T2bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the **llava-phi3** model that we installed to request a description of the images:"
      ],
      "metadata": {
        "id": "UGOxDj66T2bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "response2 = ollama.chat(model='llava-phi3', messages=[\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': 'What is this image about?',\n",
        "        'images': [f'{didiersalazar_pictures_path}/pics/example1.png'] #Image with the dog\n",
        "    },\n",
        "])\n",
        "\n",
        "display(Markdown(response2['message']['content']))"
      ],
      "metadata": {
        "trusted": true,
        "id": "gbCnbrRiT2bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = ollama.chat(model='llava-phi3', messages=[\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': 'What is this image about?',\n",
        "        'images': [f'{didiersalazar_pictures_path}/pics/example2.jpg'] #Image with the cat\n",
        "    },\n",
        "])\n",
        "\n",
        "display(Markdown(response3['message']['content']))"
      ],
      "metadata": {
        "trusted": true,
        "id": "-MhSxjWrT2bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ** >>> Exercise 10 (Take home): **  \n",
        "\n",
        "Try asking the model with one image of your choosing. Is the description accurate? Why?"
      ],
      "metadata": {
        "id": "sxZYEFmrT2bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n",
        "response3 = ollama.chat(model='llava-phi3', messages=[\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': 'Is their any human in the picture?',\n",
        "        'images': [f'{didiersalazar_pictures_path}/pics/example2.jpg'] #Image with the cat\n",
        "    },\n",
        "])\n",
        "\n",
        "display(Markdown(response3['message']['content']))"
      ],
      "metadata": {
        "trusted": true,
        "id": "SxyMIbDhT2bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n",
        "response3 = ollama.chat(model='llava-phi3', messages=[\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': 'Do you want to build a snowman with it?',\n",
        "        'images': [f'{didiersalazar_pictures_path}/pics/example2.jpg'] #Image with the cat\n",
        "    },\n",
        "])\n",
        "\n",
        "display(Markdown(response3['message']['content']))"
      ],
      "metadata": {
        "id": "BtiILCYtY_Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n",
        "response3 = ollama.chat(model='llava-phi3', messages=[\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': 'Is the cat able to eat bird?',\n",
        "        'images': [f'{didiersalazar_pictures_path}/pics/example2.jpg'] #Image with the cat\n",
        "    },\n",
        "])\n",
        "\n",
        "display(Markdown(response3['message']['content']))"
      ],
      "metadata": {
        "id": "sZ5afSC1ZkUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So in the first questionit show's model can identify item. However it can't give an answer of opinion."
      ],
      "metadata": {
        "id": "HTsyH8BxZKX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.3 Retrieval-Augmented Generation (RAG)\n",
        "RAG (Retrieval-Augmented Generation) is a technique where a language model combines document retrieval with text generation. In RAG, a retrieval system first finds relevant documents or text chunks, and then the language model uses this retrieved information to generate a more informed and accurate response. This method enhances the model's ability to answer questions by grounding its responses in real, external data.\n",
        "\n",
        "In the following code, we will load a webpage as a document, which allows us to retrieve text from a URL. After loading the content, we will split the document into smaller, manageable chunks, making it easier for our model to process. Then, we'll generate embeddings for these chunks with a specified LLM model (e.g., Llama3.2). These embeddings will be stored in a vector database, which enables us to perform similarity searches. By setting up this retrieval system, we can use a RAG chain to answer questions. The retriever finds relevant text chunks from the document based on a query, and the LLM generates a response by incorporating this retrieved information, making the answers more grounded and accurate."
      ],
      "metadata": {
        "id": "ici0AHuXT2bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "import bs4\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "llm_model = \"llama3.2\" #You can change to the one of your preference\n",
        "\n",
        "# Function to load, split, and retrieve documents\n",
        "def load_and_retrieve_docs(url):\n",
        "    loader = WebBaseLoader(\n",
        "        web_paths=(url,),\n",
        "        bs_kwargs=dict()\n",
        "    )\n",
        "    docs = loader.load() #We will load the URL that will serve as our data source\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) #We will divide the URL in chunks of text for easier comparison in the vector space\n",
        "    splits = text_splitter.split_documents(docs)\n",
        "    #print(splits) #You can print this to see how the chunks in the url where split\n",
        "    embeddings = OllamaEmbeddings(model=llm_model) #Generating embeddings with our chosen model\n",
        "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) #Our vector space for comparison\n",
        "    return vectorstore.as_retriever()\n",
        "\n",
        "url=\"https://www.ibm.com/topics/large-language-models\"\n",
        "# Create the retriever\n",
        "retriever = load_and_retrieve_docs(url)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs) #Format the retrieved docs in an orderly manner for prompting\n",
        "\n",
        "# Define the Ollama LLM function\n",
        "def ollama_llm(question, context):\n",
        "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
        "    response = ollama.chat(model='llama3.2', messages=[{'role': 'user', 'content': formatted_prompt}])\n",
        "    return response['message']['content']\n",
        "\n",
        "# Define the RAG chain\n",
        "def rag_chain(question):\n",
        "    retrieved_docs = retriever.invoke(question)\n",
        "    formatted_context = format_docs(retrieved_docs)\n",
        "    return ollama_llm(question, formatted_context)\n",
        "\n",
        "# Use the RAG chain\n",
        "result = rag_chain(\"What are the related solutions of IBM with LLMs?\")\n",
        "display(Markdown(result))"
      ],
      "metadata": {
        "trusted": true,
        "id": "EqtheStkT2bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Actual content in the URL:**\n",
        "![pic11.png](https://github.com/didiersalazar/DM2024-Lab2-Master/blob/main/pics/pic11.png?raw=true)\n",
        "\n",
        "source: https://www.ibm.com/topics/large-language-models"
      ],
      "metadata": {
        "id": "zJVpGKWMT2bI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ** >>> Exercise 11 (Take home): **  \n",
        "\n",
        "Try to modify the code to make it accept **three URLs**, or **three text documents** of your choosing. After modifying it, make **three prompts/questions** with information that can be found in each of the documents/urls, **compare the accuracy of the response** with the actual answer. Investigate and discuss the advantages and disadvantages of RAG systems."
      ],
      "metadata": {
        "id": "NDLYIqrBT2bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n",
        "import ollama\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "llm_model = \"llama3.2\"  # Choose LLM model\n",
        "\n",
        "# Function to load and retrieve docs from multiple URLs or documents\n",
        "def load_and_retrieve_docs(sources):\n",
        "    retrievers = []\n",
        "\n",
        "    for source in sources:\n",
        "        if source.startswith(\"http\"):  # URL source\n",
        "            loader = WebBaseLoader(web_paths=(source,), bs_kwargs=dict())\n",
        "            docs = loader.load()\n",
        "        else:  # File source\n",
        "            with open(source, \"r\", encoding=\"utf-8\") as file:\n",
        "                text = file.read()\n",
        "                docs = [{\"page_content\": text}]\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "        splits = text_splitter.split_documents(docs)\n",
        "        embeddings = OllamaEmbeddings(model=llm_model)\n",
        "        retrievers.append(Chroma.from_documents(documents=splits, embedding=embeddings).as_retriever())\n",
        "\n",
        "    # Combine retrievers into a single retriever\n",
        "    return retrievers\n",
        "\n",
        "# Function to format retrieved docs\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)  # Combine chunks\n",
        "\n",
        "# Ollama LLM for querying\n",
        "def ollama_llm(question, context):\n",
        "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
        "    response = ollama.chat(model=llm_model, messages=[{'role': 'user', 'content': formatted_prompt}])\n",
        "    return response['message']['content']\n",
        "\n",
        "# RAG chain to retrieve from all retrievers\n",
        "def rag_chain(question, retrievers):\n",
        "    retrieved_context = []\n",
        "    for retriever in retrievers:\n",
        "        retrieved_docs = retriever.invoke(question)\n",
        "        retrieved_context.extend(retrieved_docs)\n",
        "    formatted_context = format_docs(retrieved_context)\n",
        "    return ollama_llm(question, formatted_context)\n",
        "\n",
        "# Define sources (URLs or text files)\n",
        "sources = [\n",
        "    \"https://www.ibm.com/topics/large-language-models\",  # Example URL 1\n",
        "    \"https://www.ibm.com/cloud/what-is-cloud-computing\",  # Example URL 2\n",
        "    \"https://www.ibm.com/security/data-breach\"  # Example URL 3\n",
        "]\n",
        "\n",
        "# Load retrievers for sources\n",
        "retrievers = load_and_retrieve_docs(sources)\n",
        "\n",
        "# Use RAG chain for querying\n",
        "result = rag_chain(\"What are the related solutions of IBM with LLMs?\", retrievers)\n",
        "display(Markdown(result))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "PRUcYrDqT2bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.4 Generating LLM Embeddings:\n",
        "LLM embeddings are dense vector representations of text generated by Large Language Models. These embeddings, like we have already seen in the lab, capture the semantic meaning and relationships between words, phrases, or even entire documents by mapping them into a high-dimensional space where similar pieces of text are placed closer together. What makes LLM embeddings special is that they are contextual and rich in meaning, meaning the same word can have different embeddings based on its surrounding context.\n",
        "\n",
        "For example, the word **\"bank\"** would have different embeddings in the sentences **\"I sat by the river bank\"** and **\"I deposited money in the bank.\"** This ability to understand and encode context enables LLM embeddings to outperform traditional techniques (like TF-IDF or one-hot encoding) by providing a deeper, more nuanced representation of language.\n",
        "\n",
        "Additionally, LLM embeddings are pre-trained on vast amounts of data, allowing them to generalize well across different tasks (like classification, clustering, or similarity detection) without the need for extensive retraining. This makes them highly valuable in many natural language processing tasks today.\n",
        "\n",
        "**Now let's generate some embeddings with llama 3.2 for our dataset:**"
      ],
      "metadata": {
        "id": "0ngTP7DqT2bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ollama\n",
        "\n",
        "# Let's copy our dataframes for training and testing\n",
        "df_train = train_df\n",
        "df_test = test_df\n",
        "# Define a function to generate embeddings\n",
        "def generate_embeddings(row,text_column_name='text'):\n",
        "    embeddings = ollama.embeddings(\n",
        "        model='llama3.2',\n",
        "        prompt=row[text_column_name],\n",
        "    )\n",
        "    return embeddings[\"embedding\"]"
      ],
      "metadata": {
        "trusted": true,
        "id": "SPoTFYCHT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the text column\n",
        "column_name = 'text'\n",
        "\n",
        "# Apply the function to the specified column and store the result in a new column 'embeddings'\n",
        "df_train['embeddings'] = df_train.apply(lambda row: generate_embeddings(row, column_name), axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "4gKgfdkxT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['embeddings'] = df_test.apply(lambda row: generate_embeddings(row, column_name), axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "V_PnDB5pT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train #We can see the new column with the embeddings"
      ],
      "metadata": {
        "trusted": true,
        "id": "GWoCuqzAT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test #We can see the new column with the embeddings"
      ],
      "metadata": {
        "trusted": true,
        "id": "XcfRCamhT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's train some models with these embeddings:\n",
        "\n",
        "**KNeighborsClassifier (KNN)**: KNN is a simple, instance-based machine learning algorithm used for classification. It works by finding the 'k' nearest neighbors to a data point based on a distance metric (e.g., Euclidean distance) and assigning the most common class among those neighbors to the data point. KNN is non-parametric, meaning it doesnt assume a specific form for the underlying data distribution, and it classifies points based on their similarity to other points in the training set. It's easy to understand and implement, though it can become computationally expensive with large datasets."
      ],
      "metadata": {
        "id": "Cv1uzteeT2bJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Let's use the new Llama 3.2 embeddings as our training features and the emotions as our labels\n",
        "X_train = df_train[\"embeddings\"].tolist()\n",
        "y_train = df_train['emotion']\n",
        "\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8kg9pLFPT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train[\"embeddings\"][0]) # Llama 3.2 embedding dimension is 3072"
      ],
      "metadata": {
        "trusted": true,
        "id": "0odAAvgJT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = df_test[\"embeddings\"].tolist()\n",
        "y_test = df_test['emotion']\n",
        "\n",
        "# Predicting the label for the test data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "#Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'KNN Accuracy: {accuracy}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "95JKWCiNT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## precision, recall, f1-score,\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZsmniWBfT2bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## check by confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm2 = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
        "plot_confusion_matrix(cm2, classes=my_tags, title='Confusion matrix for classification with \\nLLM Embeddings - KNN')"
      ],
      "metadata": {
        "trusted": true,
        "id": "EVRJqqUdT2bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's also try to apply our **Neural Network** to these embeddings:"
      ],
      "metadata": {
        "id": "EZoHQzpXT2bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_llama_train = np.vstack(df_train[\"embeddings\"].to_numpy()) #Defining our train set"
      ],
      "metadata": {
        "trusted": true,
        "id": "PbRJU_Y8T2bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_llama_test = np.vstack(df_test[\"embeddings\"].to_numpy()) #Defining our test set"
      ],
      "metadata": {
        "trusted": true,
        "id": "CUyrJvjuT2bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_llama_train.shape #(Number of data, Llama 3.2 embedding size)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pR8QfcZxT2bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_llama_test.shape #(Number of data, Llama 3.2 embedding size)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RzLRD0uuT2bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One-hot encoding our labels\n",
        "y_train_llama = label_encode(label_encoder, y_train)\n",
        "y_test_llama = label_encode(label_encoder, y_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "VEZcgHVdT2bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I/O check\n",
        "input_shape_llama = len(X_llama_train[0])\n",
        "print('input_shape: ', input_shape_llama)\n",
        "\n",
        "output_shape = len(label_encoder.classes_)\n",
        "print('output_shape: ', output_shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mCKyYCp4T2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We try the same Neural Network Model Again\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import ReLU, Softmax\n",
        "\n",
        "# input layer\n",
        "model_input = Input(shape=(input_shape_llama, ))  # 3072\n",
        "X = model_input\n",
        "\n",
        "# 1st hidden layer\n",
        "X_W1 = Dense(units=64)(X)  # 64\n",
        "H1 = ReLU()(X_W1)\n",
        "\n",
        "# 2nd hidden layer\n",
        "H1_W2 = Dense(units=64)(H1)  # 64\n",
        "H2 = ReLU()(H1_W2)\n",
        "\n",
        "# output layer\n",
        "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
        "H3 = Softmax()(H2_W3)\n",
        "\n",
        "model_output = H3\n",
        "\n",
        "# create model\n",
        "model = Model(inputs=[model_input], outputs=[model_output])\n",
        "\n",
        "# loss function & optimizer\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# show model construction\n",
        "model.summary() #We can notice that our parameter numbers went up because of the increase in the dimension of our input"
      ],
      "metadata": {
        "trusted": true,
        "id": "pwftrA6NT2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "csv_logger = CSVLogger('training_log_2.csv')\n",
        "\n",
        "# training setting\n",
        "epochs = 25\n",
        "batch_size = 32\n",
        "\n",
        "# training!\n",
        "history = model.fit(X_llama_train, y_train_llama,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[csv_logger],\n",
        "                    validation_data = (X_llama_test, y_test_llama))\n",
        "print('training finish')"
      ],
      "metadata": {
        "trusted": true,
        "id": "pD24BNLoT2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## predict\n",
        "pred_result = model.predict(X_llama_test, batch_size=128)\n",
        "pred_result[:5]"
      ],
      "metadata": {
        "trusted": true,
        "id": "_RliPS0LT2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_result = label_decode(label_encoder, pred_result)\n",
        "pred_result[:5]"
      ],
      "metadata": {
        "trusted": true,
        "id": "lfsNJuZST2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "#Accuracy\n",
        "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test_llama), pred_result), 2)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "5naOXr6uT2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's take a look at the training log\n",
        "training_log = pd.DataFrame()\n",
        "training_log = pd.read_csv(\"training_log_2.csv\")\n",
        "training_log"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lc_NloUwT2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true=label_decode(label_encoder, y_test_llama), y_pred=pred_result))"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y5TfuhfoT2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## check by confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm3 = confusion_matrix(y_true=label_decode(label_encoder, y_test_llama), y_pred=pred_result)\n",
        "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
        "plot_confusion_matrix(cm3, classes=my_tags, title='Confusion matrix for classification with \\nLLM Embeddings - Neural Network')"
      ],
      "metadata": {
        "trusted": true,
        "id": "Qw4KwBKAT2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** >>> Exercise 12 (Take home): **\n",
        "\n",
        "Follow Exercise 6 again and Plot the Training and Validation Accuracy and Loss for the results of this Neural Network. Compare the results of both KNN and the NN we just implemented. Discuss about why we obtained these results with the LLM Embeddings compared to the results of the other models implemented in this Lab."
      ],
      "metadata": {
        "id": "Ra5gqgBNT2bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the training logs for both models\n",
        "nn_log = pd.read_csv(\"training_log_2.csv\")  # Neural Network log\n",
        "knn_log = pd.read_csv(\"training_log.csv\")   # KNN log (from Exercise 6)\n",
        "\n",
        "# Plot NN Training and Validation Accuracy and Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy Comparison\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(nn_log['epoch'], nn_log['accuracy'], label='NN Train Accuracy', color='blue')\n",
        "plt.plot(nn_log['epoch'], nn_log['val_accuracy'], label='NN Val Accuracy', color='red')\n",
        "plt.title('Neural Network: Training vs. Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss Comparison\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(nn_log['epoch'], nn_log['loss'], label='NN Train Loss', color='blue')\n",
        "plt.plot(nn_log['epoch'], nn_log['val_loss'], label='NN Val Loss', color='red')\n",
        "plt.title('Neural Network: Training vs. Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "aSeMhEjCT2bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.5 Few-Shot Prompting Classification:\n",
        "Few-shot prompting classification for LLMs involves giving the model a few labeled examples (typically 5 or fewer) within a prompt to guide it in performing a classification task. Instead of needing extensive training, the LLM uses these examples to understand the task and classify new inputs. This approach is significant in current research because it allows LLMs to perform well on tasks with minimal labeled data, reducing the need for large training datasets and making it highly flexible for various NLP tasks, including those in low-resource languages or niche domains.\n",
        "\n",
        "In this lab exercise, we will explore zero-shot, 1-shot, and 5-shot prompting for classification using an LLM:\n",
        "\n",
        "- Zero-shot means the model performs classification without seeing any examples beforehand.\n",
        "- 1-shot provides the model with just one labeled example per class to guide its classification.\n",
        "- 5-shot gives the model five labeled examples per class to improve its understanding of the task.\n",
        "\n",
        "Since processing large datasets can be computationally demanding, we will only sample 20 test texts per emotion for the classification task, allowing us to test the model's performance more efficiently without using the entire test set.\n",
        "\n",
        "**Process order: Explanation Prompt -> Examples + labels (if it is not zero-shot) -> Text to classify**\n",
        "\n",
        "**Recommendation for the explanation prompt:** Explain to the model that it is a classification model of certain labels, and to only output the label word, and no other explanation. In this case if the model does not follow the instructions we are retrying the same text until it outputs one of the accepted labels for it."
      ],
      "metadata": {
        "id": "hp83DCZiT2bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Define the emotion labels\n",
        "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
        "# Define the model to use for few-shot prompting\n",
        "model_ollama = \"llama3.2\"\n",
        "\n",
        "# Function to sample examples per emotion category\n",
        "def sample_few_shots(df, emotions, num_samples=5):\n",
        "    few_shot_examples = {}\n",
        "    for emotion in emotions:\n",
        "        few_shot_examples[emotion] = df[df['emotion'] == emotion].sample(n=num_samples, random_state=42)\n",
        "    return few_shot_examples\n",
        "\n",
        "# Function to build the prompt based on the number of examples (few-shot, 1-shot, zero-shot)\n",
        "def build_prompt(examples, emotions, num_shots=5):\n",
        "    classification_instructions = \"\"\"\n",
        "You are an emotion classification model. You will be given a text from social media and your task is to classify the text into one of the following emotion categories: anger, fear, joy, or sadness.\n",
        "You must only output one of these four labels. Do not provide any additional information or explanation. Just output the emotion label as one word.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = classification_instructions + \"\\n\\n\"\n",
        "\n",
        "    if num_shots > 0:\n",
        "        prompt += f\"Examples: \\n\"\n",
        "        for emotion in emotions:\n",
        "            for _, row in examples[emotion].iterrows():\n",
        "                prompt += f\"Text: {row['text']}\\nEmotion: {emotion}\\n\\n\" #Show the examples in the same format it will be shown for the classification text\n",
        "                if num_shots == 1:  # If 1-shot, break after the first example for each emotion\n",
        "                    break\n",
        "    return prompt\n",
        "\n",
        "# Function to classify using the LLM with retry for incorrect responses\n",
        "def classify_with_llm(test_text, prompt_base):\n",
        "    valid_emotions = ['anger', 'fear', 'joy', 'sadness']\n",
        "    response = None\n",
        "    while not response or response not in valid_emotions:\n",
        "        full_prompt = f\"{prompt_base}\\nClassification:\\nText: {test_text}\\nEmotion: \" #The classification text will leave the emotion label to be filled in by the LLM\n",
        "        result = ollama.chat(model=model_ollama, messages=[\n",
        "            {'role': 'user', 'content': full_prompt}\n",
        "        ])\n",
        "        response = result['message']['content'].strip().lower()  # Clean and standardize the response\n",
        "        if response not in valid_emotions:  # Retry if not a valid response\n",
        "            print(f\"Invalid response: {response}. Asking for reclassification.\")\n",
        "    return response\n",
        "\n",
        "# Main function to run the experiment with the option for zero-shot, 1-shot, or 5-shot prompting\n",
        "def run_experiment(df_train, df_test, test_samples=5, num_shots=5):\n",
        "    # Sample examples for few-shot prompting based on num_shots\n",
        "    if num_shots > 0:\n",
        "        few_shot_examples = sample_few_shots(df_train, emotions, num_samples=num_shots)\n",
        "        prompt_base = build_prompt(few_shot_examples, emotions, num_shots=num_shots)\n",
        "    else:\n",
        "        prompt_base = build_prompt(None, emotions, num_shots=0)  # Zero-shot has no examples\n",
        "\n",
        "    # Prepare to classify the test set\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    print(prompt_base)\n",
        "    # Sample 20 examples per emotion for the test set to classify\n",
        "    test_samples = sample_few_shots(df_test, emotions, num_samples=test_samples)\n",
        "\n",
        "    # Classify 20 test examples (5 from each category) and save predictions\n",
        "    for emotion in emotions:\n",
        "        for _, test_row in test_samples[emotion].iterrows():\n",
        "            test_text = test_row['text']\n",
        "            predicted_emotion = classify_with_llm(test_text, prompt_base)\n",
        "            predictions.append(predicted_emotion)\n",
        "            true_labels.append(emotion)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Classification report\n",
        "    print(classification_report(y_true=true_labels, y_pred=predictions))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_true=true_labels, y_pred=predictions)\n",
        "    my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
        "    plot_confusion_matrix(cm, classes=my_tags, title=f'Confusion matrix for classification with \\n{num_shots}-shot prompting')"
      ],
      "metadata": {
        "trusted": true,
        "id": "uOTf24XDT2bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of running the experiment with zero-shot prompting\n",
        "run_experiment(df_train, df_test, test_samples=20, num_shots=0)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ufIoZ3MxT2bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of running the experiment with 1-shot prompting\n",
        "run_experiment(df_train, df_test, test_samples=20, num_shots=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "DbyIIYGvT2bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of running the experiment with 5-shot prompting\n",
        "run_experiment(df_train, df_test, test_samples=20, num_shots=5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "KaZ_70T4T2bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** >>> Exercise 13 (Take home): **\n",
        "\n",
        "Compare and discuss the results of the zero-shot, 1-shot and 5-shot classification."
      ],
      "metadata": {
        "id": "nyF3gs0NT2bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we just compare the accuracy, It's not obiously improve by increasing shot. Recall value increase slightly after giving shot. With ao little data,we must consider overfitting excit."
      ],
      "metadata": {
        "id": "dVQ1Tm7lcO4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.6 Extra LLM Materials:\n",
        "So this will be it for the lab, but here are some extra materials if you would like to explore:\n",
        "- How to use Gemini's LLM API from Google: [Gemini Collab](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/get-started/python.ipynb?fbclid=IwZXh0bgNhZW0CMTEAAR0-gg7cDIuaGfkeN5U3rusSNKj2jj7bIsL45sZWaM0NbTE7BSNtfzBeEGE_aem_yT5wAuL_G5E21iuuCYJXwA#scrollTo=hskqSKnJUHvp) (Free with some restrictions to the requests per minute.\n",
        "\n",
        "- How to use OpenAI ChatGPT model's API (Not Free API): [Basics Video](https://www.youtube.com/watch?v=e9P7FLi5Zy8), [Basics GitHub](https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb), [RAG's Basics Video](https://www.youtube.com/watch?v=9AXP7tCI9PI&t=300s), [RAG's Basics GitHub](https://github.com/techleadhd/chatgpt-retrieval)\n",
        "\n",
        "- **Advanced topic - QLoRA (Quantized Low-Rank Adapter):** QLoRA is a method used to make fine-tuning large language models more efficient. It works by adding a small, trainable part (LoRA) to a pre-trained model, while keeping the rest of the model frozen. At the same time, it reduces the size of the models data using a process called quantization, which makes the model require less memory. This allows you to fine-tune large models without needing as much computational power, making it easier to adapt models for specific tasks. Materials: [Paper GitHub](https://github.com/artidoro/qlora?tab=readme-ov-file), [Llama 3 Application Video](https://www.youtube.com/watch?v=YJNbgusTSF0&t=512s),[Llama 3 Application GitHub](https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)"
      ],
      "metadata": {
        "id": "kU-0z0btT2bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_fF1woa8YTp5"
      }
    }
  ]
}